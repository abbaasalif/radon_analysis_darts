{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\Anaconda\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "d:\\Anaconda\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "13\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "35\n",
      "36\n",
      "37\n",
      "39\n",
      "41\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "xls = pd.ExcelFile('../data.xlsx')\n",
    "df = {}\n",
    "for num in xls.sheet_names[1:-1]:\n",
    "    df[num] = pd.read_excel(xls, num) \n",
    "for key in df:\n",
    "    df[key]['SyncDate'] = pd.to_datetime(df[key]['SyncDate'])\n",
    "    df[key].sort_values(by='SyncDate', ascending=True, inplace=True)\n",
    "    df[key]['SyncDate'] = df[key]['SyncDate'].dt.floor('H')\n",
    "    df[key] = df[key].resample('H', on = 'SyncDate').mean()\n",
    "    df[key].drop_duplicates(inplace=True)\n",
    "df_radon = pd.DataFrame(index=df['50'].index)\n",
    "for key in df:\n",
    "    print(key)\n",
    "    df_radon[f'Radon_{key}'] = df[key]['Radon']\n",
    "df_radon = df_radon.interpolate(method='linear', limit_direction='both')\n",
    "df_radon = df_radon.T\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "values = sc.fit_transform(df_radon.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Reduce the dimensions using the following techniques\n",
    "### Linear Techniques\n",
    "- PCA\n",
    "- ICA\n",
    "- Truncated SVD\n",
    "\n",
    "### Non-linear techniques\n",
    "- t-SNE\n",
    "- Isomap\n",
    "- MDS\n",
    "- UMAP\n",
    "- Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2022-05-11 18:00:00', '2022-05-11 19:00:00',\n",
       "               '2022-05-11 20:00:00', '2022-05-11 21:00:00',\n",
       "               '2022-05-11 22:00:00', '2022-05-11 23:00:00',\n",
       "               '2022-05-12 00:00:00', '2022-05-12 01:00:00',\n",
       "               '2022-05-12 02:00:00', '2022-05-12 03:00:00',\n",
       "               ...\n",
       "               '2022-08-07 14:00:00', '2022-08-07 15:00:00',\n",
       "               '2022-08-07 16:00:00', '2022-08-07 17:00:00',\n",
       "               '2022-08-07 18:00:00', '2022-08-07 19:00:00',\n",
       "               '2022-08-07 20:00:00', '2022-08-07 21:00:00',\n",
       "               '2022-08-07 22:00:00', '2022-08-07 23:00:00'],\n",
       "              dtype='datetime64[ns]', name='SyncDate', length=2012, freq=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radon.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "d:\\Anaconda\\envs\\ML\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE, MDS, Isomap, LocallyLinearEmbedding\n",
    "from umap import UMAP\n",
    "pca = PCA(n_components=3)\n",
    "values_pca = pca.fit_transform(values)\n",
    "ica = FastICA(n_components=3)\n",
    "values_ica = ica.fit_transform(values)\n",
    "svd = TruncatedSVD(n_components=3)\n",
    "values_svd = svd.fit_transform(values)\n",
    "tsne = TSNE(n_components=3)\n",
    "values_tsne = tsne.fit_transform(values)\n",
    "mds = MDS(n_components=3)\n",
    "values_mds = mds.fit_transform(values)\n",
    "isomap = Isomap(n_components=3)\n",
    "values_isomap = isomap.fit_transform(values)\n",
    "umap = UMAP(n_components=3)\n",
    "values_umap = umap.fit_transform(values)\n",
    "lle = LocallyLinearEmbedding(n_components=3)\n",
    "values_lle = lle.fit_transform(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting POT\n",
      "  Downloading POT-0.8.2-cp37-cp37m-win_amd64.whl (192 kB)\n",
      "     -------------------------------------- 192.9/192.9 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\anaconda\\envs\\ml\\lib\\site-packages (from POT) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\alifbros\\appdata\\roaming\\python\\python37\\site-packages (from POT) (1.4.1)\n",
      "Installing collected packages: POT\n",
      "Successfully installed POT-0.8.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance preservation measures to comapare dimensionality reduction methods\\\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cdist\n",
    "from ot import wasserstein_1d\n",
    "#code from https://github.com/KenLauLab/DR-structure-preservation/blob/master/fcc_utils.py\n",
    "def distance_stats(pre, post, downsample=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Tests for correlation between Euclidean cell-cell distances before and after \n",
    "    transformation by a function or DR algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    pre : np.array\n",
    "        vector of unique distances (pdist()) or distance matrix of shape (n_cells, \n",
    "        m_cells), i.e. (cdist()) before transformation/projection\n",
    "    post : np.array\n",
    "        vector of unique distances (pdist()) or distance matrix of shape (n_cells, \n",
    "        m_cells), i.e. (cdist()) after transformation/projection\n",
    "    downsample : int, optional (default=False)\n",
    "        number of distances to downsample to. maximum of 50M (~10k cells, if \n",
    "        symmetrical) is recommended for performance.\n",
    "    verbose : bool, optional (default=True)\n",
    "        print progress statements to console\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    pre : np.array\n",
    "        vector of normalized unique distances (pdist()) or distance matrix of shape \n",
    "        (n_cells, m_cells), before transformation/projection\n",
    "    post : np.array\n",
    "        vector of normalized unique distances (pdist()) or distance matrix of shape \n",
    "        (n_cells, m_cells), after transformation/projection\n",
    "    corr_stats : list\n",
    "        output of `pearsonr()` function correlating the two normalized unique distance \n",
    "        vectors\n",
    "    EMD : float\n",
    "        output of `wasserstein_1d()` function calculating the Earth Mover's Distance \n",
    "        between the two normalized unique distance vectors\n",
    "\n",
    "    1) performs Pearson correlation of distance distributions\n",
    "    2) normalizes unique distances using min-max standardization for each dataset\n",
    "    3) calculates Wasserstein or Earth-Mover's Distance for normalized distance \n",
    "    distributions between datasets\n",
    "    \"\"\"\n",
    "    # make sure the number of cells in each matrix is the same\n",
    "    assert (\n",
    "        pre.shape == post.shape\n",
    "    ), 'Matrices contain different number of distances.\\n{} in \"pre\"\\n{} in \"post\"\\n'.format(\n",
    "        pre.shape[0], post.shape[0]\n",
    "    )\n",
    "\n",
    "    # if distance matrix (mA x mB, result of cdist), flatten to unique cell-cell distances\n",
    "    if pre.ndim == 2:\n",
    "        if verbose:\n",
    "            print(\"Flattening pre-transformation distance matrix into 1D array...\")\n",
    "        # if symmetric, only keep unique values (above diagonal)\n",
    "        if np.allclose(pre, pre.T, rtol=1e-05, atol=1e-08):\n",
    "            pre = pre[np.triu_indices(n=pre.shape[0], k=1)]\n",
    "        # otherwise, flatten all distances\n",
    "        else:\n",
    "            pre = pre.flatten()\n",
    "\n",
    "    # if distance matrix (mA x mB, result of cdist), flatten to unique cell-cell distances\n",
    "    if post.ndim == 2:\n",
    "        if verbose:\n",
    "            print(\"Flattening post-transformation distance matrix into 1D array...\")\n",
    "        # if symmetric, only keep unique values (above diagonal)\n",
    "        if np.allclose(post, post.T, rtol=1e-05, atol=1e-08):\n",
    "            post = post[np.triu_indices(n=post.shape[0], k=1)]\n",
    "        # otherwise, flatten all distances\n",
    "        else:\n",
    "            post = post.flatten()\n",
    "\n",
    "    # if dataset is large, randomly downsample to reasonable number of distances for calculation\n",
    "    if downsample:\n",
    "        assert downsample < len(\n",
    "            pre\n",
    "        ), \"Must provide downsample value smaller than total number of cell-cell distances provided in pre and post\"\n",
    "        if verbose:\n",
    "            print(\"Downsampling to {} total cell-cell distances...\".format(downsample))\n",
    "        idx = np.random.choice(np.arange(len(pre)), downsample, replace=False)\n",
    "        pre = pre[idx]\n",
    "        post = post[idx]\n",
    "\n",
    "    # calculate correlation coefficient using Pearson correlation\n",
    "    if verbose:\n",
    "        print(\"Correlating distances\")\n",
    "    corr_stats = pearsonr(x=pre, y=post)\n",
    "\n",
    "    # min-max normalization for fair comparison of probability distributions\n",
    "    if verbose:\n",
    "        print(\"Normalizing unique distances\")\n",
    "    pre -= pre.min()\n",
    "    pre /= pre.ptp()\n",
    "\n",
    "    post -= post.min()\n",
    "    post /= post.ptp()\n",
    "\n",
    "    # calculate EMD for the distance matrices\n",
    "    # by default, downsample to 50M distances to speed processing time,\n",
    "    # since this function often breaks with larger distributions\n",
    "    if verbose:\n",
    "        print(\"Calculating Earth-Mover's Distance between distributions\")\n",
    "    if len(pre) > 50000000:\n",
    "        idx = np.random.choice(np.arange(len(pre)), 50000000, replace=False)\n",
    "        pre_EMD = pre[idx]\n",
    "        post_EMD = post[idx]\n",
    "        EMD = wasserstein_1d(pre_EMD, post_EMD)\n",
    "    else:\n",
    "        EMD = wasserstein_1d(pre, post)\n",
    "\n",
    "    return pre, post, corr_stats, EMD\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_original  = cdist(values, values)\n",
    "distances_pca = cdist(values_pca, values_pca)\n",
    "distances_ica = cdist(values_ica, values_ica)\n",
    "distances_svd = cdist(values_svd, values_svd)\n",
    "distances_tsne = cdist(values_tsne, values_tsne)\n",
    "distances_mds = cdist(values_mds, values_mds)\n",
    "distances_isomap = cdist(values_isomap, values_isomap)\n",
    "distances_umap = cdist(values_umap, values_umap)\n",
    "distances_lle = cdist(values_lle, values_lle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n",
      "Flattening pre-transformation distance matrix into 1D array...\n",
      "Flattening post-transformation distance matrix into 1D array...\n",
      "Correlating distances\n",
      "Normalizing unique distances\n",
      "Calculating Earth-Mover's Distance between distributions\n"
     ]
    }
   ],
   "source": [
    "_,_, corr_stats_pca, EMD_pca=distance_stats(distances_original, distances_pca)\n",
    "_,_, corr_stats_ica, EMD_ica=distance_stats(distances_original, distances_ica)\n",
    "_,_, corr_stats_svd, EMD_svd=distance_stats(distances_original, distances_svd)\n",
    "_,_, corr_stats_tsne, EMD_tsne=distance_stats(distances_original, distances_tsne)\n",
    "_,_, corr_stats_mds, EMD_mds=distance_stats(distances_original, distances_mds)\n",
    "_,_, corr_stats_isomap, EMD_isomap=distance_stats(distances_original, distances_isomap)\n",
    "_,_, corr_stats_umap, EMD_umap=distance_stats(distances_original, distances_umap)\n",
    "_,_, corr_stats_lle, EMD_lle=distance_stats(distances_original, distances_lle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of distances from pca and original data: 0.985756846895964\n",
      "Earth Movers Distance of distances from pca and original data: 0.04718091922523203\n",
      "Correlation of distances from ica and original data: 0.8510747492241625\n",
      "Earth Movers Distance of distances from ica and original data: 0.0255375971387131\n",
      "Correlation of distances from svd and original data: 0.9857568477609754\n",
      "Earth Movers Distance of distances from svd and original data: 0.047180924386551054\n",
      "Correlation of distances from tsne and original data: -0.06772904379583916\n",
      "Earth Movers Distance of distances from tsne and original data: 0.24167059742928232\n",
      "Correlation of distances from mds and original data: 0.9876746376467508\n",
      "Earth Movers Distance of distances from mds and original data: 0.014573028344839502\n",
      "Correlation of distances from isomap and original data: 0.9494366427956001\n",
      "Earth Movers Distance of distances from isomap and original data: 0.051321859716701314\n",
      "Correlation of distances from umap and original data: 0.6498772896150102\n",
      "Earth Movers Distance of distances from umap and original data: 0.04636795710652815\n",
      "Correlation of distances from lle and original data: 0.5278076441779563\n",
      "Earth Movers Distance of distances from lle and original data: 0.1328465697572898\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation of distances from pca and original data:\",corr_stats_pca[0])\n",
    "print(\"Earth Movers Distance of distances from pca and original data:\",EMD_pca)\n",
    "print(\"Correlation of distances from ica and original data:\",corr_stats_ica[0])\n",
    "print(\"Earth Movers Distance of distances from ica and original data:\",EMD_ica)\n",
    "print(\"Correlation of distances from svd and original data:\",corr_stats_svd[0])\n",
    "print(\"Earth Movers Distance of distances from svd and original data:\",EMD_svd)\n",
    "print(\"Correlation of distances from tsne and original data:\",corr_stats_tsne[0])\n",
    "print(\"Earth Movers Distance of distances from tsne and original data:\",EMD_tsne)\n",
    "print(\"Correlation of distances from mds and original data:\",corr_stats_mds[0])\n",
    "print(\"Earth Movers Distance of distances from mds and original data:\",EMD_mds)\n",
    "print(\"Correlation of distances from isomap and original data:\",corr_stats_isomap[0])\n",
    "print(\"Earth Movers Distance of distances from isomap and original data:\",EMD_isomap)\n",
    "print(\"Correlation of distances from umap and original data:\",corr_stats_umap[0])\n",
    "print(\"Earth Movers Distance of distances from umap and original data:\",EMD_umap)\n",
    "print(\"Correlation of distances from lle and original data:\",corr_stats_lle[0])\n",
    "print(\"Earth Movers Distance of distances from lle and original data:\",EMD_lle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def joint_plot_distance_correlation(pre, post, figsize, cmap, save_to=None):\n",
    "    plt.close()  # close matplotlib figure frofm __init__() and start over with seaborn.JointGrid()\n",
    "    fig = sns.JointGrid(\n",
    "            x=pre, y=post, space=0, height=figsize[0]\n",
    "        )\n",
    "    fig.plot_joint(plt.hist2d, bins=50, cmap=cmap)\n",
    "    sns.kdeplot(\n",
    "            x=pre,\n",
    "            color=self.palette[-1],\n",
    "            shade=False,\n",
    "            bw_method=0.01,\n",
    "            ax=fig.ax_marg_x,\n",
    "        )\n",
    "    sns.kdeplot(\n",
    "            y=self.post,\n",
    "            color=self.palette[2],\n",
    "            shade=False,\n",
    "            bw_method=0.01,\n",
    "            ax=self.fig.ax_marg_y,\n",
    "        )\n",
    "    self.fig.ax_joint.plot(\n",
    "            np.linspace(max(min(self.pre), min(self.post)), 1, 100),\n",
    "            np.linspace(max(min(self.pre), min(self.post)), 1, 100),\n",
    "            linestyle=\"dashed\",\n",
    "            color=self.palette[-1],\n",
    "        )  # plot identity line as reference for regression\n",
    "    if self.labels:\n",
    "            plt.xlabel(self.labels[0], fontsize=\"xx-large\", color=self.palette[-1])\n",
    "            plt.ylabel(self.labels[1], fontsize=\"xx-large\", color=self.palette[2])\n",
    "\n",
    "    plt.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "    if save_to is None:\n",
    "        return\n",
    "    else:\n",
    "        plt.savefig(fname=save_to, transparent=True, bbox_inches=\"tight\", dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8809126b2e3f6bd67afd8dec0aaf136102c3339cf179547b748c69a78a732e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
