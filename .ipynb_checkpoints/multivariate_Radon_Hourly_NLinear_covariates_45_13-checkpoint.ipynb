{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "QUANTILES = [0.01, 0.1, 0.2, 0.5, 0.8, 0.9, 0.99] \n",
    "\n",
    "SPLIT = 0.9         # train/test %\n",
    "\n",
    "FIGSIZE = (9, 6)\n",
    "\n",
    "\n",
    "qL1, qL2 = 0.01, 0.10        # percentiles of predictions: lower bounds\n",
    "qU1, qU2 = 1-qL1, 1-qL2,     # upper bounds derived from lower bounds\n",
    "label_q1 = f'{int(qU1 * 100)} / {int(qL1 * 100)} percentile band'\n",
    "label_q2 = f'{int(qU2 * 100)} / {int(qL2 * 100)} percentile band'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import missingno as mno\n",
    "import pywt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import TransformerModel, NBEATSModel, NHiTSModel, XGBModel, RNNModel, BlockRNNModel, TFTModel, TCNModel, DLinearModel, NLinearModel\n",
    "from darts.models import AutoARIMA, LinearRegressionModel, RegressionEnsembleModel\n",
    "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis\n",
    "from darts.metrics import mape, rmse, smape\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.tuner import lr_finder\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42, workers=True)\n",
    "pd.set_option(\"display.precision\",2)\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2022-05-08 00:16:30 - 2023-06-06 12:25:38\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "4\n",
      "2022-05-08 00:17:23 - 2023-06-06 12:26:06\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "7\n",
      "2022-04-01 10:18:57 - 2023-06-06 12:30:25\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "8\n",
      "2022-04-04 18:52:46 - 2023-06-06 12:27:12\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "10\n",
      "2022-05-08 00:56:00 - 2023-06-06 23:02:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "11\n",
      "2022-05-08 00:50:01 - 2023-06-07 12:13:32\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "13\n",
      "2022-05-08 00:33:33 - 2023-06-06 23:09:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "15\n",
      "2022-05-08 00:39:00 - 2023-06-06 23:59:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "16\n",
      "2022-05-08 00:47:00 - 2023-06-06 23:00:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "18\n",
      "2022-05-08 00:49:00 - 2023-06-06 23:07:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "19\n",
      "2022-05-08 00:51:00 - 2023-06-06 23:36:00\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "20\n",
      "2022-05-08 00:54:00 - 2023-06-07 12:40:49\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "21\n",
      "2022-05-08 00:56:15 - 2023-06-07 12:59:58\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "22\n",
      "2022-05-08 00:18:00 - 2023-06-07 12:52:52\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "25\n",
      "2022-05-08 00:03:36 - 2023-06-07 12:38:18\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "26\n",
      "2022-05-08 00:02:00 - 2023-06-07 12:09:59\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "29\n",
      "2022-05-08 00:21:08 - 2023-06-07 12:56:18\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "30\n",
      "2022-05-08 00:50:24 - 2023-06-06 12:24:21\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "31\n",
      "2022-05-08 00:49:08 - 2023-06-06 12:25:42\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "32\n",
      "2022-05-08 00:07:33 - 2023-06-06 12:42:28\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "35\n",
      "2022-05-08 00:44:21 - 2023-06-06 12:43:39\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "37\n",
      "2022-05-08 00:04:11 - 2023-06-06 12:37:59\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "39\n",
      "2022-05-08 00:37:45 - 2023-06-06 12:28:55\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "41\n",
      "2022-05-08 00:14:21 - 2023-06-06 12:21:14\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "43\n",
      "2022-05-08 00:45:03 - 2023-06-06 12:44:59\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "45\n",
      "2022-05-08 00:26:45 - 2023-06-06 12:29:28\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "46\n",
      "2022-05-08 00:24:56 - 2023-06-06 12:28:30\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "49\n",
      "2022-05-08 00:19:51 - 2023-06-06 12:47:26\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n",
      "50\n",
      "2022-05-11 18:29:15 - 2023-06-06 12:22:48\n",
      "2022-05-11 19:00:00 - 2023-06-06 12:00:00\n"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile('df_radon_combined.xlsx')\n",
    "\n",
    "df_radon = {}\n",
    "for num in xls.sheet_names[2:]:\n",
    "    df_radon[num] = pd.read_excel(xls, num) \n",
    "\n",
    "#remove these indexes\n",
    "devices = ['1', '2', '5', '9', '17', '23', '27', '28', '36', '44', '48']\n",
    "for key in list(df_radon):\n",
    "    if key in devices:\n",
    "        del df_radon[key]\n",
    "\n",
    "for key in df_radon:\n",
    "    print(key)\n",
    "    df_radon[key]['SyncDate'] = pd.to_datetime(df_radon[key]['SyncDate'])\n",
    "    print(f\"{df_radon[key]['SyncDate'].min()} - {df_radon[key]['SyncDate'].max()}\")\n",
    "    df_radon[key].sort_values(by='SyncDate', ascending=True, inplace=True)\n",
    "    df_radon[key]['SyncDate'] = df_radon[key]['SyncDate'].dt.floor('H')\n",
    "    df_radon[key] = df_radon[key].resample('H', on = 'SyncDate').mean()\n",
    "    df_radon[key] = df_radon[key].interpolate(method='linear', limit_direction='both')\n",
    "    start_time = pd.to_datetime('2022-05-11T18:29:00.000000000')\n",
    "    end_time = pd.to_datetime('2023-06-06T12:00:00.000000000')\n",
    "    df_radon[key] = df_radon[key][(df_radon[key].index >= start_time) & (df_radon[key].index <= end_time)]\n",
    "    print(f\"{df_radon[key].index.min()} - {df_radon[key].index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radon 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_radon['45'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising the Radon signal\n",
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db4', level=5):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    n = len(x) \n",
    "    sigma = (1/0.6745) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    if len(x) % 2 ==0:\n",
    "        return pywt.waverec(coeff, wavelet, mode='per')\n",
    "    else:\n",
    "        return pywt.waverec(coeff, wavelet, mode='per')[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = df['Radon'].copy()\n",
    "wavelet_name='coif9'\n",
    "filtered = wavelet_denoising(signal, wavelet=wavelet_name, level=4)\n",
    "df['Radon'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station = pd.read_csv('weather_data_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station.drop('Date', axis=1, inplace=True)\n",
    "weather_station['Simple Date'] = pd.to_datetime(weather_station['Simple Date'])\n",
    "weather_station.sort_values(by='Simple Date', ascending=True, inplace=True)\n",
    "weather_station['Simple Date'] = weather_station['Simple Date'].dt.floor('H')\n",
    "weather_station = weather_station.resample('H', on = 'Simple Date').mean()\n",
    "weather_station = weather_station.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outdoor h Temperature (°F)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Wind Gust (mph)</th>\n",
       "      <th>Max Daily Gust (mph)</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "      <th>Hourly Rain (in/hr)</th>\n",
       "      <th>Event Rain (in)</th>\n",
       "      <th>Daily Rain (in)</th>\n",
       "      <th>Weekly Rain (in)</th>\n",
       "      <th>Monthly Rain (in)</th>\n",
       "      <th>Yearly Rain (in)</th>\n",
       "      <th>Relative Pressure (inHg)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Ultra-Violet Radiation Index</th>\n",
       "      <th>Solar Radiation (W/m^2)</th>\n",
       "      <th>Absolute Pressure (inHg)</th>\n",
       "      <th>Avg Wind Direction (10 mins) (°)</th>\n",
       "      <th>Avg Wind Speed (10 mins) (mph)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-10 00:00:00</th>\n",
       "      <td>55.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>305.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.13</td>\n",
       "      <td>90.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.13</td>\n",
       "      <td>305.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 01:00:00</th>\n",
       "      <td>54.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>302.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.12</td>\n",
       "      <td>91.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.12</td>\n",
       "      <td>302.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 02:00:00</th>\n",
       "      <td>53.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>298.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.11</td>\n",
       "      <td>91.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.11</td>\n",
       "      <td>298.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 03:00:00</th>\n",
       "      <td>52.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>302.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.12</td>\n",
       "      <td>92.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.12</td>\n",
       "      <td>302.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-10 04:00:00</th>\n",
       "      <td>51.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>305.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.13</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.13</td>\n",
       "      <td>305.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07 19:00:00</th>\n",
       "      <td>80.57</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9.20</td>\n",
       "      <td>287.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.66</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.17</td>\n",
       "      <td>28.66</td>\n",
       "      <td>311.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07 20:00:00</th>\n",
       "      <td>77.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>309.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.66</td>\n",
       "      <td>58.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.92</td>\n",
       "      <td>28.66</td>\n",
       "      <td>310.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07 21:00:00</th>\n",
       "      <td>74.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>304.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.66</td>\n",
       "      <td>63.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.66</td>\n",
       "      <td>304.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07 22:00:00</th>\n",
       "      <td>73.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>9.20</td>\n",
       "      <td>307.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.68</td>\n",
       "      <td>67.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.68</td>\n",
       "      <td>305.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07 23:00:00</th>\n",
       "      <td>72.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>306.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.69</td>\n",
       "      <td>69.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.69</td>\n",
       "      <td>306.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9456 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Outdoor h Temperature (°F)  Wind Speed (mph)  \\\n",
       "Simple Date                                                         \n",
       "2022-05-10 00:00:00                       55.74              0.00   \n",
       "2022-05-10 01:00:00                       54.79              0.00   \n",
       "2022-05-10 02:00:00                       53.88              0.00   \n",
       "2022-05-10 03:00:00                       52.49              0.00   \n",
       "2022-05-10 04:00:00                       51.70              0.00   \n",
       "...                                         ...               ...   \n",
       "2023-06-07 19:00:00                       80.57              0.02   \n",
       "2023-06-07 20:00:00                       77.16              0.00   \n",
       "2023-06-07 21:00:00                       74.54              0.00   \n",
       "2023-06-07 22:00:00                       73.51              0.06   \n",
       "2023-06-07 23:00:00                       72.15              0.00   \n",
       "\n",
       "                     Wind Gust (mph)  Max Daily Gust (mph)  \\\n",
       "Simple Date                                                  \n",
       "2022-05-10 00:00:00             0.00                  0.00   \n",
       "2022-05-10 01:00:00             0.00                  0.00   \n",
       "2022-05-10 02:00:00             0.00                  0.00   \n",
       "2022-05-10 03:00:00             0.00                  0.00   \n",
       "2022-05-10 04:00:00             0.00                  0.00   \n",
       "...                              ...                   ...   \n",
       "2023-06-07 19:00:00             0.18                  9.20   \n",
       "2023-06-07 20:00:00             0.00                  9.20   \n",
       "2023-06-07 21:00:00             0.00                  9.20   \n",
       "2023-06-07 22:00:00             0.09                  9.20   \n",
       "2023-06-07 23:00:00             0.00                  9.20   \n",
       "\n",
       "                     Wind Direction (°)  Hourly Rain (in/hr)  Event Rain (in)  \\\n",
       "Simple Date                                                                     \n",
       "2022-05-10 00:00:00              305.17                 0.00             0.00   \n",
       "2022-05-10 01:00:00              302.58                 0.00             0.00   \n",
       "2022-05-10 02:00:00              298.92                 0.00             0.00   \n",
       "2022-05-10 03:00:00              302.92                 0.00             0.00   \n",
       "2022-05-10 04:00:00              305.17                 0.00             0.00   \n",
       "...                                 ...                  ...              ...   \n",
       "2023-06-07 19:00:00              287.08                 0.00             0.00   \n",
       "2023-06-07 20:00:00              309.83                 0.00             0.00   \n",
       "2023-06-07 21:00:00              304.83                 0.00             0.00   \n",
       "2023-06-07 22:00:00              307.83                 0.00             0.00   \n",
       "2023-06-07 23:00:00              306.58                 0.00             0.00   \n",
       "\n",
       "                     Daily Rain (in)  Weekly Rain (in)  Monthly Rain (in)  \\\n",
       "Simple Date                                                                 \n",
       "2022-05-10 00:00:00             0.00              0.00               0.76   \n",
       "2022-05-10 01:00:00             0.00              0.00               0.76   \n",
       "2022-05-10 02:00:00             0.00              0.00               0.76   \n",
       "2022-05-10 03:00:00             0.00              0.00               0.76   \n",
       "2022-05-10 04:00:00             0.00              0.00               0.76   \n",
       "...                              ...               ...                ...   \n",
       "2023-06-07 19:00:00             0.00              0.02               0.02   \n",
       "2023-06-07 20:00:00             0.00              0.02               0.02   \n",
       "2023-06-07 21:00:00             0.00              0.02               0.02   \n",
       "2023-06-07 22:00:00             0.00              0.02               0.02   \n",
       "2023-06-07 23:00:00             0.00              0.02               0.02   \n",
       "\n",
       "                     Yearly Rain (in)  Relative Pressure (inHg)  Humidity (%)  \\\n",
       "Simple Date                                                                     \n",
       "2022-05-10 00:00:00             22.72                     29.13         90.67   \n",
       "2022-05-10 01:00:00             22.72                     29.12         91.58   \n",
       "2022-05-10 02:00:00             22.72                     29.11         91.42   \n",
       "2022-05-10 03:00:00             22.72                     29.12         92.83   \n",
       "2022-05-10 04:00:00             22.72                     29.13         94.00   \n",
       "...                               ...                       ...           ...   \n",
       "2023-06-07 19:00:00             83.42                     28.66         54.42   \n",
       "2023-06-07 20:00:00             83.42                     28.66         58.42   \n",
       "2023-06-07 21:00:00             83.42                     28.66         63.08   \n",
       "2023-06-07 22:00:00             83.42                     28.68         67.33   \n",
       "2023-06-07 23:00:00             83.42                     28.69         69.67   \n",
       "\n",
       "                     Ultra-Violet Radiation Index  Solar Radiation (W/m^2)  \\\n",
       "Simple Date                                                                  \n",
       "2022-05-10 00:00:00                          0.00                     0.00   \n",
       "2022-05-10 01:00:00                          0.00                     0.00   \n",
       "2022-05-10 02:00:00                          0.00                     0.00   \n",
       "2022-05-10 03:00:00                          0.00                     0.00   \n",
       "2022-05-10 04:00:00                          0.00                     0.00   \n",
       "...                                           ...                      ...   \n",
       "2023-06-07 19:00:00                          0.00                    33.17   \n",
       "2023-06-07 20:00:00                          0.00                     5.92   \n",
       "2023-06-07 21:00:00                          0.00                     0.00   \n",
       "2023-06-07 22:00:00                          0.00                     0.00   \n",
       "2023-06-07 23:00:00                          0.00                     0.00   \n",
       "\n",
       "                     Absolute Pressure (inHg)  \\\n",
       "Simple Date                                     \n",
       "2022-05-10 00:00:00                     29.13   \n",
       "2022-05-10 01:00:00                     29.12   \n",
       "2022-05-10 02:00:00                     29.11   \n",
       "2022-05-10 03:00:00                     29.12   \n",
       "2022-05-10 04:00:00                     29.13   \n",
       "...                                       ...   \n",
       "2023-06-07 19:00:00                     28.66   \n",
       "2023-06-07 20:00:00                     28.66   \n",
       "2023-06-07 21:00:00                     28.66   \n",
       "2023-06-07 22:00:00                     28.68   \n",
       "2023-06-07 23:00:00                     28.69   \n",
       "\n",
       "                     Avg Wind Direction (10 mins) (°)  \\\n",
       "Simple Date                                             \n",
       "2022-05-10 00:00:00                            305.42   \n",
       "2022-05-10 01:00:00                            302.67   \n",
       "2022-05-10 02:00:00                            298.83   \n",
       "2022-05-10 03:00:00                            302.83   \n",
       "2022-05-10 04:00:00                            305.67   \n",
       "...                                               ...   \n",
       "2023-06-07 19:00:00                            311.17   \n",
       "2023-06-07 20:00:00                            310.00   \n",
       "2023-06-07 21:00:00                            304.75   \n",
       "2023-06-07 22:00:00                            305.83   \n",
       "2023-06-07 23:00:00                            306.50   \n",
       "\n",
       "                     Avg Wind Speed (10 mins) (mph)  \n",
       "Simple Date                                          \n",
       "2022-05-10 00:00:00                            0.00  \n",
       "2022-05-10 01:00:00                            0.00  \n",
       "2022-05-10 02:00:00                            0.00  \n",
       "2022-05-10 03:00:00                            0.00  \n",
       "2022-05-10 04:00:00                            0.00  \n",
       "...                                             ...  \n",
       "2023-06-07 19:00:00                            0.02  \n",
       "2023-06-07 20:00:00                            0.00  \n",
       "2023-06-07 21:00:00                            0.00  \n",
       "2023-06-07 22:00:00                            0.00  \n",
       "2023-06-07 23:00:00                            0.00  \n",
       "\n",
       "[9456 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in weather_station.columns:\n",
    "    df[column] = weather_station[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Radon</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outdoor h Temperature (°F)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Wind Gust (mph)</th>\n",
       "      <th>Max Daily Gust (mph)</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "      <th>Hourly Rain (in/hr)</th>\n",
       "      <th>...</th>\n",
       "      <th>Weekly Rain (in)</th>\n",
       "      <th>Monthly Rain (in)</th>\n",
       "      <th>Yearly Rain (in)</th>\n",
       "      <th>Relative Pressure (inHg)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Ultra-Violet Radiation Index</th>\n",
       "      <th>Solar Radiation (W/m^2)</th>\n",
       "      <th>Absolute Pressure (inHg)</th>\n",
       "      <th>Avg Wind Direction (10 mins) (°)</th>\n",
       "      <th>Avg Wind Speed (10 mins) (mph)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyncDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-11 19:00:00</th>\n",
       "      <td>30.05</td>\n",
       "      <td>37.00</td>\n",
       "      <td>7.36</td>\n",
       "      <td>88.00</td>\n",
       "      <td>77.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.80</td>\n",
       "      <td>313.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.00</td>\n",
       "      <td>63.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.24</td>\n",
       "      <td>29.00</td>\n",
       "      <td>307.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 20:00:00</th>\n",
       "      <td>30.05</td>\n",
       "      <td>41.00</td>\n",
       "      <td>6.93</td>\n",
       "      <td>83.00</td>\n",
       "      <td>74.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>302.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.01</td>\n",
       "      <td>68.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.57</td>\n",
       "      <td>29.01</td>\n",
       "      <td>301.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 21:00:00</th>\n",
       "      <td>30.06</td>\n",
       "      <td>45.00</td>\n",
       "      <td>6.52</td>\n",
       "      <td>80.00</td>\n",
       "      <td>72.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>301.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.02</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.02</td>\n",
       "      <td>302.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 22:00:00</th>\n",
       "      <td>30.07</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.00</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>306.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.05</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.05</td>\n",
       "      <td>305.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 23:00:00</th>\n",
       "      <td>30.10</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>76.00</td>\n",
       "      <td>69.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>301.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.06</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.06</td>\n",
       "      <td>304.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 08:00:00</th>\n",
       "      <td>29.89</td>\n",
       "      <td>57.50</td>\n",
       "      <td>9.67</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.51</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.25</td>\n",
       "      <td>307.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.89</td>\n",
       "      <td>86.08</td>\n",
       "      <td>0.42</td>\n",
       "      <td>104.46</td>\n",
       "      <td>28.89</td>\n",
       "      <td>307.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 09:00:00</th>\n",
       "      <td>29.89</td>\n",
       "      <td>57.00</td>\n",
       "      <td>9.14</td>\n",
       "      <td>79.00</td>\n",
       "      <td>76.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.80</td>\n",
       "      <td>317.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.90</td>\n",
       "      <td>74.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>333.82</td>\n",
       "      <td>28.90</td>\n",
       "      <td>311.42</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 10:00:00</th>\n",
       "      <td>29.90</td>\n",
       "      <td>49.00</td>\n",
       "      <td>8.69</td>\n",
       "      <td>86.00</td>\n",
       "      <td>81.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.17</td>\n",
       "      <td>308.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.89</td>\n",
       "      <td>68.08</td>\n",
       "      <td>5.00</td>\n",
       "      <td>547.11</td>\n",
       "      <td>28.89</td>\n",
       "      <td>315.25</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 11:00:00</th>\n",
       "      <td>29.79</td>\n",
       "      <td>47.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>78.00</td>\n",
       "      <td>83.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.52</td>\n",
       "      <td>6.90</td>\n",
       "      <td>287.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.90</td>\n",
       "      <td>64.08</td>\n",
       "      <td>5.83</td>\n",
       "      <td>636.88</td>\n",
       "      <td>28.90</td>\n",
       "      <td>315.83</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 12:00:00</th>\n",
       "      <td>30.02</td>\n",
       "      <td>68.00</td>\n",
       "      <td>7.81</td>\n",
       "      <td>74.00</td>\n",
       "      <td>85.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.90</td>\n",
       "      <td>303.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.88</td>\n",
       "      <td>60.83</td>\n",
       "      <td>5.83</td>\n",
       "      <td>655.52</td>\n",
       "      <td>28.88</td>\n",
       "      <td>294.25</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9378 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AirPressure  Humidity  Radon  Temperature  \\\n",
       "SyncDate                                                         \n",
       "2022-05-11 19:00:00        30.05     37.00   7.36        88.00   \n",
       "2022-05-11 20:00:00        30.05     41.00   6.93        83.00   \n",
       "2022-05-11 21:00:00        30.06     45.00   6.52        80.00   \n",
       "2022-05-11 22:00:00        30.07     49.00   6.12        77.00   \n",
       "2022-05-11 23:00:00        30.10     50.00   5.73        76.00   \n",
       "...                          ...       ...    ...          ...   \n",
       "2023-06-06 08:00:00        29.89     57.50   9.67        77.00   \n",
       "2023-06-06 09:00:00        29.89     57.00   9.14        79.00   \n",
       "2023-06-06 10:00:00        29.90     49.00   8.69        86.00   \n",
       "2023-06-06 11:00:00        29.79     47.00   8.26        78.00   \n",
       "2023-06-06 12:00:00        30.02     68.00   7.81        74.00   \n",
       "\n",
       "                     Outdoor h Temperature (°F)  Wind Speed (mph)  \\\n",
       "SyncDate                                                            \n",
       "2022-05-11 19:00:00                       77.07              0.00   \n",
       "2022-05-11 20:00:00                       74.87              0.00   \n",
       "2022-05-11 21:00:00                       72.88              0.00   \n",
       "2022-05-11 22:00:00                       71.14              0.00   \n",
       "2022-05-11 23:00:00                       69.29              0.00   \n",
       "...                                         ...               ...   \n",
       "2023-06-06 08:00:00                       69.51              0.29   \n",
       "2023-06-06 09:00:00                       76.43              0.43   \n",
       "2023-06-06 10:00:00                       81.18              0.68   \n",
       "2023-06-06 11:00:00                       83.35              0.57   \n",
       "2023-06-06 12:00:00                       85.52              0.76   \n",
       "\n",
       "                     Wind Gust (mph)  Max Daily Gust (mph)  \\\n",
       "SyncDate                                                     \n",
       "2022-05-11 19:00:00             0.09                  5.80   \n",
       "2022-05-11 20:00:00             0.00                  5.80   \n",
       "2022-05-11 21:00:00             0.00                  5.80   \n",
       "2022-05-11 22:00:00             0.00                  5.80   \n",
       "2022-05-11 23:00:00             0.00                  5.80   \n",
       "...                              ...                   ...   \n",
       "2023-06-06 08:00:00             1.03                  2.25   \n",
       "2023-06-06 09:00:00             1.67                  4.80   \n",
       "2023-06-06 10:00:00             2.05                  6.17   \n",
       "2023-06-06 11:00:00             2.52                  6.90   \n",
       "2023-06-06 12:00:00             2.33                  6.90   \n",
       "\n",
       "                     Wind Direction (°)  Hourly Rain (in/hr)  ...  \\\n",
       "SyncDate                                                      ...   \n",
       "2022-05-11 19:00:00              313.08                 0.00  ...   \n",
       "2022-05-11 20:00:00              302.08                 0.00  ...   \n",
       "2022-05-11 21:00:00              301.67                 0.00  ...   \n",
       "2022-05-11 22:00:00              306.00                 0.00  ...   \n",
       "2022-05-11 23:00:00              301.50                 0.00  ...   \n",
       "...                                 ...                  ...  ...   \n",
       "2023-06-06 08:00:00              307.83                 0.00  ...   \n",
       "2023-06-06 09:00:00              317.17                 0.00  ...   \n",
       "2023-06-06 10:00:00              308.50                 0.00  ...   \n",
       "2023-06-06 11:00:00              287.25                 0.00  ...   \n",
       "2023-06-06 12:00:00              303.50                 0.00  ...   \n",
       "\n",
       "                     Weekly Rain (in)  Monthly Rain (in)  Yearly Rain (in)  \\\n",
       "SyncDate                                                                     \n",
       "2022-05-11 19:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 20:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 21:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 22:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 23:00:00              0.00               0.76             22.72   \n",
       "...                               ...                ...               ...   \n",
       "2023-06-06 08:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 09:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 10:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 11:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 12:00:00              0.02               0.02             83.42   \n",
       "\n",
       "                     Relative Pressure (inHg)  Humidity (%)  \\\n",
       "SyncDate                                                      \n",
       "2022-05-11 19:00:00                     29.00         63.75   \n",
       "2022-05-11 20:00:00                     29.01         68.42   \n",
       "2022-05-11 21:00:00                     29.02         73.75   \n",
       "2022-05-11 22:00:00                     29.05         73.75   \n",
       "2022-05-11 23:00:00                     29.06         74.58   \n",
       "...                                       ...           ...   \n",
       "2023-06-06 08:00:00                     28.89         86.08   \n",
       "2023-06-06 09:00:00                     28.90         74.75   \n",
       "2023-06-06 10:00:00                     28.89         68.08   \n",
       "2023-06-06 11:00:00                     28.90         64.08   \n",
       "2023-06-06 12:00:00                     28.88         60.83   \n",
       "\n",
       "                     Ultra-Violet Radiation Index  Solar Radiation (W/m^2)  \\\n",
       "SyncDate                                                                     \n",
       "2022-05-11 19:00:00                          0.00                    21.24   \n",
       "2022-05-11 20:00:00                          0.00                     2.57   \n",
       "2022-05-11 21:00:00                          0.00                     0.00   \n",
       "2022-05-11 22:00:00                          0.00                     0.00   \n",
       "2022-05-11 23:00:00                          0.00                     0.00   \n",
       "...                                           ...                      ...   \n",
       "2023-06-06 08:00:00                          0.42                   104.46   \n",
       "2023-06-06 09:00:00                          2.75                   333.82   \n",
       "2023-06-06 10:00:00                          5.00                   547.11   \n",
       "2023-06-06 11:00:00                          5.83                   636.88   \n",
       "2023-06-06 12:00:00                          5.83                   655.52   \n",
       "\n",
       "                     Absolute Pressure (inHg)  \\\n",
       "SyncDate                                        \n",
       "2022-05-11 19:00:00                     29.00   \n",
       "2022-05-11 20:00:00                     29.01   \n",
       "2022-05-11 21:00:00                     29.02   \n",
       "2022-05-11 22:00:00                     29.05   \n",
       "2022-05-11 23:00:00                     29.06   \n",
       "...                                       ...   \n",
       "2023-06-06 08:00:00                     28.89   \n",
       "2023-06-06 09:00:00                     28.90   \n",
       "2023-06-06 10:00:00                     28.89   \n",
       "2023-06-06 11:00:00                     28.90   \n",
       "2023-06-06 12:00:00                     28.88   \n",
       "\n",
       "                     Avg Wind Direction (10 mins) (°)  \\\n",
       "SyncDate                                                \n",
       "2022-05-11 19:00:00                            307.25   \n",
       "2022-05-11 20:00:00                            301.17   \n",
       "2022-05-11 21:00:00                            302.17   \n",
       "2022-05-11 22:00:00                            305.83   \n",
       "2022-05-11 23:00:00                            304.08   \n",
       "...                                               ...   \n",
       "2023-06-06 08:00:00                            307.00   \n",
       "2023-06-06 09:00:00                            311.42   \n",
       "2023-06-06 10:00:00                            315.25   \n",
       "2023-06-06 11:00:00                            315.83   \n",
       "2023-06-06 12:00:00                            294.25   \n",
       "\n",
       "                     Avg Wind Speed (10 mins) (mph)  \n",
       "SyncDate                                             \n",
       "2022-05-11 19:00:00                            0.00  \n",
       "2022-05-11 20:00:00                            0.00  \n",
       "2022-05-11 21:00:00                            0.00  \n",
       "2022-05-11 22:00:00                            0.00  \n",
       "2022-05-11 23:00:00                            0.00  \n",
       "...                                             ...  \n",
       "2023-06-06 08:00:00                            0.09  \n",
       "2023-06-06 09:00:00                            0.35  \n",
       "2023-06-06 10:00:00                            0.57  \n",
       "2023-06-06 11:00:00                            0.71  \n",
       "2023-06-06 12:00:00                            0.82  \n",
       "\n",
       "[9378 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Radon</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outdoor h Temperature (°F)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Wind Gust (mph)</th>\n",
       "      <th>Max Daily Gust (mph)</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "      <th>Hourly Rain (in/hr)</th>\n",
       "      <th>...</th>\n",
       "      <th>Weekly Rain (in)</th>\n",
       "      <th>Monthly Rain (in)</th>\n",
       "      <th>Yearly Rain (in)</th>\n",
       "      <th>Relative Pressure (inHg)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Ultra-Violet Radiation Index</th>\n",
       "      <th>Solar Radiation (W/m^2)</th>\n",
       "      <th>Absolute Pressure (inHg)</th>\n",
       "      <th>Avg Wind Direction (10 mins) (°)</th>\n",
       "      <th>Avg Wind Speed (10 mins) (mph)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyncDate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-11 19:00:00</th>\n",
       "      <td>30.05</td>\n",
       "      <td>37.00</td>\n",
       "      <td>7.36</td>\n",
       "      <td>88.00</td>\n",
       "      <td>77.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5.80</td>\n",
       "      <td>313.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.00</td>\n",
       "      <td>63.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.24</td>\n",
       "      <td>29.00</td>\n",
       "      <td>307.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 20:00:00</th>\n",
       "      <td>30.05</td>\n",
       "      <td>41.00</td>\n",
       "      <td>6.93</td>\n",
       "      <td>83.00</td>\n",
       "      <td>74.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>302.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.01</td>\n",
       "      <td>68.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.57</td>\n",
       "      <td>29.01</td>\n",
       "      <td>301.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 21:00:00</th>\n",
       "      <td>30.06</td>\n",
       "      <td>45.00</td>\n",
       "      <td>6.52</td>\n",
       "      <td>80.00</td>\n",
       "      <td>72.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>301.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.02</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.02</td>\n",
       "      <td>302.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 22:00:00</th>\n",
       "      <td>30.07</td>\n",
       "      <td>49.00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>77.00</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>306.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.05</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.05</td>\n",
       "      <td>305.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11 23:00:00</th>\n",
       "      <td>30.10</td>\n",
       "      <td>50.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>76.00</td>\n",
       "      <td>69.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>301.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.72</td>\n",
       "      <td>29.06</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.06</td>\n",
       "      <td>304.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 08:00:00</th>\n",
       "      <td>29.89</td>\n",
       "      <td>57.50</td>\n",
       "      <td>9.67</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.51</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.25</td>\n",
       "      <td>307.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.89</td>\n",
       "      <td>86.08</td>\n",
       "      <td>0.42</td>\n",
       "      <td>104.46</td>\n",
       "      <td>28.89</td>\n",
       "      <td>307.00</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 09:00:00</th>\n",
       "      <td>29.89</td>\n",
       "      <td>57.00</td>\n",
       "      <td>9.14</td>\n",
       "      <td>79.00</td>\n",
       "      <td>76.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.80</td>\n",
       "      <td>317.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.90</td>\n",
       "      <td>74.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>333.82</td>\n",
       "      <td>28.90</td>\n",
       "      <td>311.42</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 10:00:00</th>\n",
       "      <td>29.90</td>\n",
       "      <td>49.00</td>\n",
       "      <td>8.69</td>\n",
       "      <td>86.00</td>\n",
       "      <td>81.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.17</td>\n",
       "      <td>308.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.89</td>\n",
       "      <td>68.08</td>\n",
       "      <td>5.00</td>\n",
       "      <td>547.11</td>\n",
       "      <td>28.89</td>\n",
       "      <td>315.25</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 11:00:00</th>\n",
       "      <td>29.79</td>\n",
       "      <td>47.00</td>\n",
       "      <td>8.26</td>\n",
       "      <td>78.00</td>\n",
       "      <td>83.35</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.52</td>\n",
       "      <td>6.90</td>\n",
       "      <td>287.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.90</td>\n",
       "      <td>64.08</td>\n",
       "      <td>5.83</td>\n",
       "      <td>636.88</td>\n",
       "      <td>28.90</td>\n",
       "      <td>315.83</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 12:00:00</th>\n",
       "      <td>30.02</td>\n",
       "      <td>68.00</td>\n",
       "      <td>7.81</td>\n",
       "      <td>74.00</td>\n",
       "      <td>85.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.90</td>\n",
       "      <td>303.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.42</td>\n",
       "      <td>28.88</td>\n",
       "      <td>60.83</td>\n",
       "      <td>5.83</td>\n",
       "      <td>655.52</td>\n",
       "      <td>28.88</td>\n",
       "      <td>294.25</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9378 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AirPressure  Humidity  Radon  Temperature  \\\n",
       "SyncDate                                                         \n",
       "2022-05-11 19:00:00        30.05     37.00   7.36        88.00   \n",
       "2022-05-11 20:00:00        30.05     41.00   6.93        83.00   \n",
       "2022-05-11 21:00:00        30.06     45.00   6.52        80.00   \n",
       "2022-05-11 22:00:00        30.07     49.00   6.12        77.00   \n",
       "2022-05-11 23:00:00        30.10     50.00   5.73        76.00   \n",
       "...                          ...       ...    ...          ...   \n",
       "2023-06-06 08:00:00        29.89     57.50   9.67        77.00   \n",
       "2023-06-06 09:00:00        29.89     57.00   9.14        79.00   \n",
       "2023-06-06 10:00:00        29.90     49.00   8.69        86.00   \n",
       "2023-06-06 11:00:00        29.79     47.00   8.26        78.00   \n",
       "2023-06-06 12:00:00        30.02     68.00   7.81        74.00   \n",
       "\n",
       "                     Outdoor h Temperature (°F)  Wind Speed (mph)  \\\n",
       "SyncDate                                                            \n",
       "2022-05-11 19:00:00                       77.07              0.00   \n",
       "2022-05-11 20:00:00                       74.87              0.00   \n",
       "2022-05-11 21:00:00                       72.88              0.00   \n",
       "2022-05-11 22:00:00                       71.14              0.00   \n",
       "2022-05-11 23:00:00                       69.29              0.00   \n",
       "...                                         ...               ...   \n",
       "2023-06-06 08:00:00                       69.51              0.29   \n",
       "2023-06-06 09:00:00                       76.43              0.43   \n",
       "2023-06-06 10:00:00                       81.18              0.68   \n",
       "2023-06-06 11:00:00                       83.35              0.57   \n",
       "2023-06-06 12:00:00                       85.52              0.76   \n",
       "\n",
       "                     Wind Gust (mph)  Max Daily Gust (mph)  \\\n",
       "SyncDate                                                     \n",
       "2022-05-11 19:00:00             0.09                  5.80   \n",
       "2022-05-11 20:00:00             0.00                  5.80   \n",
       "2022-05-11 21:00:00             0.00                  5.80   \n",
       "2022-05-11 22:00:00             0.00                  5.80   \n",
       "2022-05-11 23:00:00             0.00                  5.80   \n",
       "...                              ...                   ...   \n",
       "2023-06-06 08:00:00             1.03                  2.25   \n",
       "2023-06-06 09:00:00             1.67                  4.80   \n",
       "2023-06-06 10:00:00             2.05                  6.17   \n",
       "2023-06-06 11:00:00             2.52                  6.90   \n",
       "2023-06-06 12:00:00             2.33                  6.90   \n",
       "\n",
       "                     Wind Direction (°)  Hourly Rain (in/hr)  ...  \\\n",
       "SyncDate                                                      ...   \n",
       "2022-05-11 19:00:00              313.08                 0.00  ...   \n",
       "2022-05-11 20:00:00              302.08                 0.00  ...   \n",
       "2022-05-11 21:00:00              301.67                 0.00  ...   \n",
       "2022-05-11 22:00:00              306.00                 0.00  ...   \n",
       "2022-05-11 23:00:00              301.50                 0.00  ...   \n",
       "...                                 ...                  ...  ...   \n",
       "2023-06-06 08:00:00              307.83                 0.00  ...   \n",
       "2023-06-06 09:00:00              317.17                 0.00  ...   \n",
       "2023-06-06 10:00:00              308.50                 0.00  ...   \n",
       "2023-06-06 11:00:00              287.25                 0.00  ...   \n",
       "2023-06-06 12:00:00              303.50                 0.00  ...   \n",
       "\n",
       "                     Weekly Rain (in)  Monthly Rain (in)  Yearly Rain (in)  \\\n",
       "SyncDate                                                                     \n",
       "2022-05-11 19:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 20:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 21:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 22:00:00              0.00               0.76             22.72   \n",
       "2022-05-11 23:00:00              0.00               0.76             22.72   \n",
       "...                               ...                ...               ...   \n",
       "2023-06-06 08:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 09:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 10:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 11:00:00              0.02               0.02             83.42   \n",
       "2023-06-06 12:00:00              0.02               0.02             83.42   \n",
       "\n",
       "                     Relative Pressure (inHg)  Humidity (%)  \\\n",
       "SyncDate                                                      \n",
       "2022-05-11 19:00:00                     29.00         63.75   \n",
       "2022-05-11 20:00:00                     29.01         68.42   \n",
       "2022-05-11 21:00:00                     29.02         73.75   \n",
       "2022-05-11 22:00:00                     29.05         73.75   \n",
       "2022-05-11 23:00:00                     29.06         74.58   \n",
       "...                                       ...           ...   \n",
       "2023-06-06 08:00:00                     28.89         86.08   \n",
       "2023-06-06 09:00:00                     28.90         74.75   \n",
       "2023-06-06 10:00:00                     28.89         68.08   \n",
       "2023-06-06 11:00:00                     28.90         64.08   \n",
       "2023-06-06 12:00:00                     28.88         60.83   \n",
       "\n",
       "                     Ultra-Violet Radiation Index  Solar Radiation (W/m^2)  \\\n",
       "SyncDate                                                                     \n",
       "2022-05-11 19:00:00                          0.00                    21.24   \n",
       "2022-05-11 20:00:00                          0.00                     2.57   \n",
       "2022-05-11 21:00:00                          0.00                     0.00   \n",
       "2022-05-11 22:00:00                          0.00                     0.00   \n",
       "2022-05-11 23:00:00                          0.00                     0.00   \n",
       "...                                           ...                      ...   \n",
       "2023-06-06 08:00:00                          0.42                   104.46   \n",
       "2023-06-06 09:00:00                          2.75                   333.82   \n",
       "2023-06-06 10:00:00                          5.00                   547.11   \n",
       "2023-06-06 11:00:00                          5.83                   636.88   \n",
       "2023-06-06 12:00:00                          5.83                   655.52   \n",
       "\n",
       "                     Absolute Pressure (inHg)  \\\n",
       "SyncDate                                        \n",
       "2022-05-11 19:00:00                     29.00   \n",
       "2022-05-11 20:00:00                     29.01   \n",
       "2022-05-11 21:00:00                     29.02   \n",
       "2022-05-11 22:00:00                     29.05   \n",
       "2022-05-11 23:00:00                     29.06   \n",
       "...                                       ...   \n",
       "2023-06-06 08:00:00                     28.89   \n",
       "2023-06-06 09:00:00                     28.90   \n",
       "2023-06-06 10:00:00                     28.89   \n",
       "2023-06-06 11:00:00                     28.90   \n",
       "2023-06-06 12:00:00                     28.88   \n",
       "\n",
       "                     Avg Wind Direction (10 mins) (°)  \\\n",
       "SyncDate                                                \n",
       "2022-05-11 19:00:00                            307.25   \n",
       "2022-05-11 20:00:00                            301.17   \n",
       "2022-05-11 21:00:00                            302.17   \n",
       "2022-05-11 22:00:00                            305.83   \n",
       "2022-05-11 23:00:00                            304.08   \n",
       "...                                               ...   \n",
       "2023-06-06 08:00:00                            307.00   \n",
       "2023-06-06 09:00:00                            311.42   \n",
       "2023-06-06 10:00:00                            315.25   \n",
       "2023-06-06 11:00:00                            315.83   \n",
       "2023-06-06 12:00:00                            294.25   \n",
       "\n",
       "                     Avg Wind Speed (10 mins) (mph)  \n",
       "SyncDate                                             \n",
       "2022-05-11 19:00:00                            0.00  \n",
       "2022-05-11 20:00:00                            0.00  \n",
       "2022-05-11 21:00:00                            0.00  \n",
       "2022-05-11 22:00:00                            0.00  \n",
       "2022-05-11 23:00:00                            0.00  \n",
       "...                                             ...  \n",
       "2023-06-06 08:00:00                            0.09  \n",
       "2023-06-06 09:00:00                            0.35  \n",
       "2023-06-06 10:00:00                            0.57  \n",
       "2023-06-06 11:00:00                            0.71  \n",
       "2023-06-06 12:00:00                            0.82  \n",
       "\n",
       "[9378 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# any missing values?\n",
    "def gaps(df):\n",
    "    if df.isnull().values.any():\n",
    "        print(\"MISSING values:\\n\")\n",
    "        mno.matrix(df)\n",
    "    else:\n",
    "        print(\"no missing values\\n\")\n",
    "gaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Radon</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outdoor h Temperature (°F)</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Wind Gust (mph)</th>\n",
       "      <th>Max Daily Gust (mph)</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "      <th>Hourly Rain (in/hr)</th>\n",
       "      <th>...</th>\n",
       "      <th>Weekly Rain (in)</th>\n",
       "      <th>Monthly Rain (in)</th>\n",
       "      <th>Yearly Rain (in)</th>\n",
       "      <th>Relative Pressure (inHg)</th>\n",
       "      <th>Humidity (%)</th>\n",
       "      <th>Ultra-Violet Radiation Index</th>\n",
       "      <th>Solar Radiation (W/m^2)</th>\n",
       "      <th>Absolute Pressure (inHg)</th>\n",
       "      <th>Avg Wind Direction (10 mins) (°)</th>\n",
       "      <th>Avg Wind Speed (10 mins) (mph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "      <td>9,378.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.10</td>\n",
       "      <td>62.16</td>\n",
       "      <td>18.13</td>\n",
       "      <td>72.54</td>\n",
       "      <td>62.98</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.70</td>\n",
       "      <td>297.71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2.88</td>\n",
       "      <td>52.63</td>\n",
       "      <td>29.02</td>\n",
       "      <td>76.37</td>\n",
       "      <td>0.96</td>\n",
       "      <td>119.51</td>\n",
       "      <td>29.02</td>\n",
       "      <td>308.30</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.14</td>\n",
       "      <td>13.24</td>\n",
       "      <td>20.50</td>\n",
       "      <td>17.99</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.49</td>\n",
       "      <td>28.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2.98</td>\n",
       "      <td>18.94</td>\n",
       "      <td>0.14</td>\n",
       "      <td>17.72</td>\n",
       "      <td>1.79</td>\n",
       "      <td>200.38</td>\n",
       "      <td>0.14</td>\n",
       "      <td>18.81</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.58</td>\n",
       "      <td>13.00</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>15.00</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.72</td>\n",
       "      <td>28.40</td>\n",
       "      <td>17.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.40</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.01</td>\n",
       "      <td>54.04</td>\n",
       "      <td>0.87</td>\n",
       "      <td>60.00</td>\n",
       "      <td>52.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>289.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>37.85</td>\n",
       "      <td>28.93</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.93</td>\n",
       "      <td>302.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.10</td>\n",
       "      <td>63.00</td>\n",
       "      <td>12.20</td>\n",
       "      <td>74.00</td>\n",
       "      <td>64.87</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.50</td>\n",
       "      <td>305.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.14</td>\n",
       "      <td>47.13</td>\n",
       "      <td>29.02</td>\n",
       "      <td>79.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.59</td>\n",
       "      <td>29.02</td>\n",
       "      <td>311.08</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.19</td>\n",
       "      <td>72.00</td>\n",
       "      <td>29.45</td>\n",
       "      <td>82.55</td>\n",
       "      <td>73.89</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.56</td>\n",
       "      <td>6.90</td>\n",
       "      <td>316.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>69.48</td>\n",
       "      <td>29.11</td>\n",
       "      <td>91.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>144.45</td>\n",
       "      <td>29.11</td>\n",
       "      <td>318.75</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.56</td>\n",
       "      <td>93.00</td>\n",
       "      <td>177.31</td>\n",
       "      <td>142.00</td>\n",
       "      <td>98.02</td>\n",
       "      <td>5.35</td>\n",
       "      <td>8.02</td>\n",
       "      <td>20.60</td>\n",
       "      <td>347.67</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>14.68</td>\n",
       "      <td>83.42</td>\n",
       "      <td>29.51</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>872.65</td>\n",
       "      <td>29.51</td>\n",
       "      <td>348.08</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AirPressure  Humidity    Radon  Temperature  \\\n",
       "count     9,378.00  9,378.00 9,378.00     9,378.00   \n",
       "mean         30.10     62.16    18.13        72.54   \n",
       "std           0.14     13.24    20.50        17.99   \n",
       "min          29.58     13.00    -0.61        15.00   \n",
       "25%          30.01     54.04     0.87        60.00   \n",
       "50%          30.10     63.00    12.20        74.00   \n",
       "75%          30.19     72.00    29.45        82.55   \n",
       "max          30.56     93.00   177.31       142.00   \n",
       "\n",
       "       Outdoor h Temperature (°F)  Wind Speed (mph)  Wind Gust (mph)  \\\n",
       "count                    9,378.00          9,378.00         9,378.00   \n",
       "mean                        62.98              0.23             0.90   \n",
       "std                         14.85              0.37             1.15   \n",
       "min                          7.12              0.00             0.00   \n",
       "25%                         52.55              0.00             0.00   \n",
       "50%                         64.87              0.03             0.37   \n",
       "75%                         73.89              0.34             1.56   \n",
       "max                         98.02              5.35             8.02   \n",
       "\n",
       "       Max Daily Gust (mph)  Wind Direction (°)  Hourly Rain (in/hr)  ...  \\\n",
       "count              9,378.00            9,378.00             9,378.00  ...   \n",
       "mean                   4.70              297.71                 0.01  ...   \n",
       "std                    3.49               28.84                 0.04  ...   \n",
       "min                    0.00                1.33                 0.00  ...   \n",
       "25%                    1.48              289.00                 0.00  ...   \n",
       "50%                    4.50              305.58                 0.00  ...   \n",
       "75%                    6.90              316.08                 0.00  ...   \n",
       "max                   20.60              347.67                 1.23  ...   \n",
       "\n",
       "       Weekly Rain (in)  Monthly Rain (in)  Yearly Rain (in)  \\\n",
       "count          9,378.00           9,378.00          9,378.00   \n",
       "mean               0.54               2.88             52.63   \n",
       "std                0.85               2.98             18.94   \n",
       "min                0.00               0.00             22.72   \n",
       "25%                0.00               0.76             37.85   \n",
       "50%                0.09               2.14             47.13   \n",
       "75%                0.72               3.72             69.48   \n",
       "max                3.90              14.68             83.42   \n",
       "\n",
       "       Relative Pressure (inHg)  Humidity (%)  Ultra-Violet Radiation Index  \\\n",
       "count                  9,378.00      9,378.00                      9,378.00   \n",
       "mean                      29.02         76.37                          0.96   \n",
       "std                        0.14         17.72                          1.79   \n",
       "min                       28.40         17.17                          0.00   \n",
       "25%                       28.93         65.00                          0.00   \n",
       "50%                       29.02         79.92                          0.00   \n",
       "75%                       29.11         91.58                          1.00   \n",
       "max                       29.51         99.00                          8.00   \n",
       "\n",
       "       Solar Radiation (W/m^2)  Absolute Pressure (inHg)  \\\n",
       "count                 9,378.00                  9,378.00   \n",
       "mean                    119.51                     29.02   \n",
       "std                     200.38                      0.14   \n",
       "min                       0.00                     28.40   \n",
       "25%                       0.00                     28.93   \n",
       "50%                       2.59                     29.02   \n",
       "75%                     144.45                     29.11   \n",
       "max                     872.65                     29.51   \n",
       "\n",
       "       Avg Wind Direction (10 mins) (°)  Avg Wind Speed (10 mins) (mph)  \n",
       "count                          9,378.00                        9,378.00  \n",
       "mean                             308.30                            0.15  \n",
       "std                               18.81                            0.31  \n",
       "min                                1.42                            0.00  \n",
       "25%                              302.17                            0.00  \n",
       "50%                              311.08                            0.00  \n",
       "75%                              318.75                            0.15  \n",
       "max                              348.08                            3.15  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df[column] = df[column].astype('float32')\n",
    "    if column == 'Radon':\n",
    "        continue\n",
    "    else:\n",
    "        for i in range(1,40):\n",
    "            df[column+'_lag_'+str(i)] = df[column].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841, 841)\n",
      "correlation with Radon:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Radon</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_26</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_25</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_27</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_24</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly Rain (in)_lag_35</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly Rain (in)_lag_36</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly Rain (in)_lag_37</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly Rain (in)_lag_38</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yearly Rain (in)_lag_39</th>\n",
       "      <td>-0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>841 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Radon\n",
       "Radon                               1.00\n",
       "Outdoor h Temperature (°F)_lag_26   0.60\n",
       "Outdoor h Temperature (°F)_lag_25   0.60\n",
       "Outdoor h Temperature (°F)_lag_27   0.60\n",
       "Outdoor h Temperature (°F)_lag_24   0.60\n",
       "...                                  ...\n",
       "Yearly Rain (in)_lag_35            -0.61\n",
       "Yearly Rain (in)_lag_36            -0.61\n",
       "Yearly Rain (in)_lag_37            -0.61\n",
       "Yearly Rain (in)_lag_38            -0.61\n",
       "Yearly Rain (in)_lag_39            -0.61\n",
       "\n",
       "[841 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correlations of features with price\n",
    "df_corr = df.corr(method=\"spearman\")\n",
    "print(df_corr.shape)\n",
    "print(\"correlation with Radon:\")\n",
    "df_corrP = pd.DataFrame(df_corr[\"Radon\"].sort_values(ascending=False))\n",
    "df_corrP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Radon</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_26</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor h Temperature (°F)_lag_25</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Radon\n",
       "Radon                               1.00\n",
       "Outdoor h Temperature (°F)_lag_26   0.60\n",
       "Outdoor h Temperature (°F)_lag_25   0.60"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest absolute correlations with Radon\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df_corrH = df_corrP[(df_corrP[\"Radon\"]) >= 0.6009]\n",
    "df_corrH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper method: correlation matrix as heatmap\n",
    "def corr_heatmap(df):\n",
    "    idx = df.corr().sort_values(\"Radon\", ascending=False).index\n",
    "    df_sorted = df.loc[:, idx]  # sort dataframe columns by their correlation \n",
    "\n",
    "    #plt.figure(figsize = (15,15))\n",
    "    sns.set(font_scale=0.75)\n",
    "    ax = sns.heatmap(df_sorted.corr().round(3), \n",
    "            annot=True, \n",
    "            square=True, \n",
    "            linewidths=.75, cmap=\"coolwarm\", \n",
    "            fmt = \".2f\", \n",
    "            annot_kws = {\"size\": 11})\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(\"correlation matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# visualize correlations with price     \n",
    "\n",
    "df4 = df[df_corrH.index]   # keep the components with at least modest correlations\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "corr_heatmap(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9378 entries, 2022-05-11 19:00:00 to 2023-06-06 12:00:00\n",
      "Freq: H\n",
      "Data columns (total 3 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Radon                              9378 non-null   float32\n",
      " 1   Outdoor h Temperature (°F)_lag_26  9378 non-null   float32\n",
      " 2   Outdoor h Temperature (°F)_lag_25  9378 non-null   float32\n",
      "dtypes: float32(3)\n",
      "memory usage: 183.2 KB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components: Index(['Radon'], dtype='object', name='component')\n",
      "duration: 390 days 17:00:00\n",
      "frequency: <Hour>\n",
      "frequency: H\n",
      "has date time index? (or else, it must have an integer index): True\n",
      "deterministic: True\n",
      "univariate: True\n"
     ]
    }
   ],
   "source": [
    "# create time series object for target variable\n",
    "ts_P = TimeSeries.from_series(df4[\"Radon\"], fill_missing_dates=True, freq=\"H\") \n",
    "\n",
    "# check attributes of the time series\n",
    "print(\"components:\", ts_P.components)\n",
    "print(\"duration:\",ts_P.duration)\n",
    "print(\"frequency:\",ts_P.freq)\n",
    "print(\"frequency:\",ts_P.freq_str)\n",
    "print(\"has date time index? (or else, it must have an integer index):\",ts_P.has_datetime_index)\n",
    "print(\"deterministic:\",ts_P.is_deterministic)\n",
    "print(\"univariate:\",ts_P.is_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "components (columns) of feature time series: Index(['Outdoor h Temperature (°F)_lag_26'], dtype='object', name='component')\n",
      "duration: 390 days 17:00:00\n",
      "frequency: <Hour>\n",
      "frequency: H\n",
      "has date time index? (or else, it must have an integer index): True\n",
      "deterministic: True\n",
      "univariate: True\n"
     ]
    }
   ],
   "source": [
    "# create time series object for the feature columns\n",
    "df_covF = df4.loc[:, df4.columns != \"Radon\"]\n",
    "df_covF = df_covF.loc[:, df_covF.columns != 'Outdoor h Temperature (°F)_lag_25']\n",
    "ts_covF = TimeSeries.from_dataframe(df_covF, fill_missing_dates=True, freq=\"H\")\n",
    "\n",
    "# check attributes of the time series\n",
    "print(\"components (columns) of feature time series:\", ts_covF.components)\n",
    "print(\"duration:\",ts_covF.duration)\n",
    "print(\"frequency:\",ts_covF.freq)\n",
    "print(\"frequency:\",ts_covF.freq_str)\n",
    "print(\"has date time index? (or else, it must have an integer index):\",ts_covF.has_datetime_index)\n",
    "print(\"deterministic:\",ts_covF.is_deterministic)\n",
    "print(\"univariate:\",ts_covF.is_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9378, 1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a 3-dimensional numpy array from a time series object\n",
    "# 3 dimensions: time (rows) / components (columns) / samples\n",
    "ar_covF = ts_covF.all_values()\n",
    "print(type(ar_covF))\n",
    "ar_covF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a pandas series or dataframe from a time series object\n",
    "df_covF = ts_covF.pd_dataframe()\n",
    "type(df_covF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start: 2022-05-11 19:00:00\n",
      "training end: 2023-05-30 13:00:00\n",
      "training duration: 383 days 18:00:00\n",
      "test start: 2023-05-30 14:00:00\n",
      "test end: 2023-06-06 12:00:00\n",
      "test duration: 6 days 22:00:00\n",
      "first and last row of scaled Radon time series:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>component</th>\n",
       "      <th>Radon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyncDate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-11 19:00:00</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 12:00:00</th>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "component            Radon\n",
       "SyncDate                  \n",
       "2022-05-11 19:00:00   0.04\n",
       "2023-06-06 12:00:00   0.05"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test split and scaling of target variable\n",
    "ts_train, ts_test = ts_P.split_after(split_point=9210)\n",
    "\n",
    "print(\"training start:\", ts_train.start_time())\n",
    "print(\"training end:\", ts_train.end_time())\n",
    "print(\"training duration:\",ts_train.duration)\n",
    "print(\"test start:\", ts_test.start_time())\n",
    "print(\"test end:\", ts_test.end_time())\n",
    "print(\"test duration:\", ts_test.duration)\n",
    "\n",
    "\n",
    "scalerP = Scaler()\n",
    "scalerP.fit_transform(ts_train)\n",
    "ts_ttrain = scalerP.transform(ts_train)\n",
    "ts_ttest = scalerP.transform(ts_test)    \n",
    "ts_t = scalerP.transform(ts_P)\n",
    "\n",
    "# make sure data are of type float\n",
    "ts_t = ts_t.astype(np.float32)\n",
    "ts_ttrain = ts_ttrain.astype(np.float32)\n",
    "ts_ttest = ts_ttest.astype(np.float32)\n",
    "\n",
    "print(\"first and last row of scaled Radon time series:\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "ts_t.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first and last row of scaled feature covariates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>component</th>\n",
       "      <th>Outdoor h Temperature (°F)_lag_26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyncDate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-11 19:00:00</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06 12:00:00</th>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "component            Outdoor h Temperature (°F)_lag_26\n",
       "SyncDate                                              \n",
       "2022-05-11 19:00:00                               0.00\n",
       "2023-06-06 12:00:00                               0.70"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test split and scaling of feature covariates\n",
    "covF_train, covF_test = ts_covF.split_after(split_point=9210)\n",
    "\n",
    "scalerF = Scaler()\n",
    "scalerF.fit_transform(covF_train)\n",
    "covF_ttrain = scalerF.transform(covF_train) \n",
    "covF_ttest = scalerF.transform(covF_test)   \n",
    "covF_t = scalerF.transform(ts_covF)  \n",
    "# covF_t = ts_covF\n",
    "# covF_ttrain = covF_train\n",
    "# covF_ttest = covF_test\n",
    "# make sure data are of type float\n",
    "covF_ttrain = covF_ttrain.astype(np.float32)\n",
    "covF_ttest = covF_ttest.astype(np.float32)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(\"first and last row of scaled feature covariates:\")\n",
    "covF_t.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first and last row of scaled target variable in training set: price:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>component</th>\n",
       "      <th>Radon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyncDate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-11 19:00:00</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30 13:00:00</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "component            Radon\n",
       "SyncDate                  \n",
       "2022-05-11 19:00:00   0.04\n",
       "2023-05-30 13:00:00   0.07"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"first and last row of scaled target variable in training set: price:\")\n",
    "ts_ttrain.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(seed_value, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ray.air import session\n",
    "from darts.utils.losses import SmapeLoss\n",
    "from torchmetrics import MetricCollection, SymmetricMeanAbsolutePercentageError, MeanAbsolutePercentageError\n",
    "def build_fit_nlinear_model(\n",
    "    model_args,\n",
    "    save_checkpoints=False,\n",
    "    callbacks=None,\n",
    "    save_model=False\n",
    "):\n",
    "#     BATCH_SIZE=64\n",
    "    MAX_EPOCHS=500\n",
    "    NR_EPOCHS_VAL_PERIOD=1\n",
    "    set_seed(42)\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), SymmetricMeanAbsolutePercentageError()])\n",
    "\n",
    "#     early_stopper = EarlyStopping(\n",
    "#         monitor=\"val_loss\",\n",
    "#         patience=5,\n",
    "#         min_delta=0.001,\n",
    "#         mode='min',\n",
    "#     )\n",
    "\n",
    "#     if callbacks is None:\n",
    "#         callbacks = [early_stopper]\n",
    "#     else:\n",
    "#         callbacks.append(early_stopper)\n",
    "    \n",
    "    #detect if GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         pl_trainer_kwargs = {\n",
    "#             \"accelerator\": \"gpu\",\n",
    "#             \"gpus\": -1,\n",
    "#             \"auto_select_gpus\": True,\n",
    "#             \"callbacks\": callbacks,\n",
    "#             \"enable_progress_bar\":False,\n",
    "#         }\n",
    "#         num_workers=8\n",
    "#     else:\n",
    "#         pl_trainer_kwargs={\n",
    "#             \"callbacks\": callbacks,\n",
    "#         }\n",
    "#         num_workers=0\n",
    "    pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"gpus\":-1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"enable_progress_bar\": False,\n",
    "        }\n",
    "    encoders={\"cyclic\": {\"future\": [\"hour\"]},\n",
    "             'transformer':Scaler()} if model_args['include_hour'] else None\n",
    "   \n",
    "\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=model_args['in_len'],\n",
    "        output_chunk_length=model_args['out_len'],\n",
    "        batch_size=model_args['batch_size'],\n",
    "        n_epochs=MAX_EPOCHS,\n",
    "        nr_epochs_val_period=NR_EPOCHS_VAL_PERIOD,\n",
    "        model_name=\"NLinear\",\n",
    "        shared_weights=False,\n",
    "        normalize=model_args['normalize'],\n",
    "        const_init=model_args['const_init'],\n",
    "        use_static_covariates=False,\n",
    "        loss_fn=SmapeLoss(),\n",
    "        optimizer_kwargs={'lr': model_args['lr']},\n",
    "        add_encoders=encoders,\n",
    "        log_tensorboard=False,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        torch_metrics=torch_metrics,\n",
    "        random_state=42\n",
    "        )\n",
    "    val_len = len(ts_test)\n",
    "    val_series = ts_ttrain[-((val_len) + model_args['in_len']) :]\n",
    "    ts_ttrain_input = ts_ttrain[:-(val_len )]\n",
    "    model.fit(  ts_ttrain_input, \n",
    "                future_covariates=covF_t,\n",
    "                val_series=val_series,\n",
    "                val_future_covariates=covF_t,)\n",
    "#     model.load_from_checkpoint(f\"{model_args['model']} RNN model\", best=True)\n",
    "    ts_tpred = model.predict(\n",
    "                series = ts_ttrain,\n",
    "                future_covariates=covF_t,\n",
    "                n = len(ts_ttest),\n",
    "                verbose=True\n",
    "    )\n",
    "    ts_q = scalerP.inverse_transform(ts_tpred)\n",
    "    q_smape = smape(ts_q, ts_test)\n",
    "    session.report({'q_smape': q_smape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fit_nlinear_model_return(\n",
    "    model_args,\n",
    "    save_checkpoints=False,\n",
    "    callbacks=None,\n",
    "    save_model=False\n",
    "):\n",
    "#     BATCH_SIZE=64\n",
    "    MAX_EPOCHS=500\n",
    "    NR_EPOCHS_VAL_PERIOD=1\n",
    "    set_seed(42)\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), SymmetricMeanAbsolutePercentageError()])\n",
    "\n",
    "#     early_stopper = EarlyStopping(\n",
    "#         monitor=\"val_loss\",\n",
    "#         patience=5,\n",
    "#         min_delta=0.001,\n",
    "#         mode='min',\n",
    "#     )\n",
    "\n",
    "#     if callbacks is None:\n",
    "#         callbacks = [early_stopper]\n",
    "#     else:\n",
    "#         callbacks.append(early_stopper)\n",
    "    \n",
    "    #detect if GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         pl_trainer_kwargs = {\n",
    "#             \"accelerator\": \"gpu\",\n",
    "#             \"gpus\": -1,\n",
    "#             \"auto_select_gpus\": True,\n",
    "#             \"callbacks\": callbacks,\n",
    "#             \"enable_progress_bar\":False,\n",
    "#         }\n",
    "#         num_workers=8\n",
    "#     else:\n",
    "#         pl_trainer_kwargs={\n",
    "#             \"callbacks\": callbacks,\n",
    "#         }\n",
    "#         num_workers=0\n",
    "    pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\":1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"enable_progress_bar\": True,\n",
    "        }\n",
    "    encoders={\"cyclic\": {\"future\": [\"hour\"]},\n",
    "             'transformer':Scaler()} if model_args['include_hour'] else None\n",
    "   \n",
    "\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=model_args['in_len'],\n",
    "        output_chunk_length=model_args['out_len'],\n",
    "        batch_size=model_args['batch_size'],\n",
    "        n_epochs=MAX_EPOCHS,\n",
    "        nr_epochs_val_period=NR_EPOCHS_VAL_PERIOD,\n",
    "        model_name=\"DLinear\",\n",
    "        shared_weights=False,\n",
    "        const_init=model_args['const_init'],\n",
    "        normalize=model_args['normalize'],\n",
    "        use_static_covariates=False,\n",
    "        loss_fn=SmapeLoss(),\n",
    "        optimizer_kwargs={'lr': model_args['lr']},\n",
    "        add_encoders=encoders,\n",
    "        log_tensorboard=False,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        torch_metrics=torch_metrics,\n",
    "        random_state=42\n",
    "        )\n",
    "    val_len = len(ts_test)\n",
    "    val_series = ts_ttrain[-((val_len) + model_args['in_len']) :]\n",
    "    ts_ttrain_input = ts_ttrain[:-(val_len )]\n",
    "    model.fit(  ts_ttrain_input, \n",
    "                future_covariates=covF_t,\n",
    "                val_series=val_series,\n",
    "                val_future_covariates=covF_t,)\n",
    "#     model.load_from_checkpoint(f\"{model_args['model']} RNN model\", best=True)\n",
    "#     ts_tpred = model.predict(\n",
    "#                 series = ts_ttrain,\n",
    "#                 past_covariates=covF_t,\n",
    "#                 n = len(ts_ttest),\n",
    "#                 verbose=True\n",
    "#     )\n",
    "#     ts_q = scalerP.inverse_transform(ts_tpred)\n",
    "#     q_smape = smape(ts_q, ts_test)\n",
    "#     session.report({'q_smape': q_smape})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:10 (running for 00:00:00.18)\n",
      "Memory usage on this node: 88.6/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 5.0/48 CPUs, 0.4/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 1/100 (1 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 3 | layer          | Linear           | 2.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 2.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 2.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m 0.011     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:15 (running for 00:00:05.20)\n",
      "Memory usage on this node: 88.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 10.0/48 CPUs, 0.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 2/100 (2 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_b0f3656a | RUNNING  | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 3 | layer          | Linear           | 2.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 2.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 2.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659835)\u001b[0m 0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:20 (running for 00:00:10.27)\n",
      "Memory usage on this node: 89.1/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 15.0/48 CPUs, 1.2000000000000002/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 3/100 (3 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_b0f3656a | RUNNING  | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                                                                       </th><th>hostname       </th><th>iterations_since_restore  </th><th>node_ip     </th><th style=\"text-align: right;\">    pid</th><th>q_smape           </th><th>time_since_restore  </th><th>time_this_iter_s  </th><th>time_total_s      </th><th style=\"text-align: right;\">  timestamp</th><th>timesteps_since_restore  </th><th>timesteps_total  </th><th>training_iteration  </th><th>trial_id  </th><th>warmup_time          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>build_fit_nlinear_model_03542bb7</td><td>2023-07-11_07-57-04</td><td>      </td><td>                </td><td>1a5f3dceb51e44d7bafda45898a530b1</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2674221</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062224</td><td>                         </td><td>                 </td><td>                    </td><td>03542bb7  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_06c8d9a1</td><td>2023-07-11_07-56-49</td><td>True  </td><td>                </td><td>c8eb9222566542b7bfb018cdee9b66db</td><td>22_batch_size=128,const_init=False,in_len=110,include_hour=True,lr=0.0001,normalize=False,out_len=19 </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2668469</td><td>169.01512145996094</td><td>50.992082595825195  </td><td>50.992082595825195</td><td>50.992082595825195</td><td style=\"text-align: right;\"> 1689062209</td><td>0                        </td><td>                 </td><td>1                   </td><td>06c8d9a1  </td><td>0.0033423900604248047</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_0a369a68</td><td>2023-07-11_07-56-01</td><td>      </td><td>                </td><td>08336a4671e4463cb764e59976702b18</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2669339</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062161</td><td>                         </td><td>                 </td><td>                    </td><td>0a369a68  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_0f3a7ae8</td><td>2023-07-11_07-54-32</td><td>      </td><td>                </td><td>1eb8a488584b4e1a8daefa44173a3e50</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660925</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062072</td><td>                         </td><td>                 </td><td>                    </td><td>0f3a7ae8  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_112beeb4</td><td>2023-07-11_07-58-11</td><td>      </td><td>                </td><td>1c3e7072408b4dc6a2443560948c4866</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683112</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062291</td><td>                         </td><td>                 </td><td>                    </td><td>112beeb4  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_12f2a79e</td><td>2023-07-11_07-54-31</td><td>      </td><td>                </td><td>e61a4b19e8b44d6397c6543744b4a41e</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660913</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062071</td><td>                         </td><td>                 </td><td>                    </td><td>12f2a79e  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_15b489a7</td><td>2023-07-11_07-57-22</td><td>      </td><td>                </td><td>3160a068c3ba457a8f5093a4026e5b3b</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2675636</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062242</td><td>                         </td><td>                 </td><td>                    </td><td>15b489a7  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_17cb88ed</td><td>2023-07-11_07-57-38</td><td>      </td><td>                </td><td>ac9b76d5a64e472a81d41d5ddaf1aed5</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678200</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062258</td><td>                         </td><td>                 </td><td>                    </td><td>17cb88ed  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_1a719bad</td><td>2023-07-11_07-56-54</td><td>      </td><td>                </td><td>41aeca489e6a4beb913304ec27c87bfd</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2673113</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062214</td><td>                         </td><td>                 </td><td>                    </td><td>1a719bad  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_1b932dac</td><td>2023-07-11_07-56-18</td><td>      </td><td>                </td><td>c316e7d45b9d4ba9b5d622033fa1196b</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2671114</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062178</td><td>                         </td><td>                 </td><td>                    </td><td>1b932dac  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_1eb26ae5</td><td>2023-07-11_07-56-54</td><td>      </td><td>                </td><td>cb1e4cdd9d6c4eb4a28889b7d025395a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2673283</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062214</td><td>                         </td><td>                 </td><td>                    </td><td>1eb26ae5  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_21b28051</td><td>2023-07-11_07-57-32</td><td>      </td><td>                </td><td>764a784432784676824cd1ba7618319a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2677019</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062252</td><td>                         </td><td>                 </td><td>                    </td><td>21b28051  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_21ea8994</td><td>2023-07-11_07-56-40</td><td>      </td><td>                </td><td>fc2fd535dfbb46dbbc1b32887fb0aadb</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2672409</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062200</td><td>                         </td><td>                 </td><td>                    </td><td>21ea8994  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_236b9e67</td><td>2023-07-11_07-57-22</td><td>      </td><td>                </td><td>b899a1ec0b6343268d83db8c60069966</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2675638</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062242</td><td>                         </td><td>                 </td><td>                    </td><td>236b9e67  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_26bb9eb6</td><td>2023-07-11_07-56-49</td><td>True  </td><td>                </td><td>4f4924b6029d4611a21449cb655ef65d</td><td>32_batch_size=64,const_init=True,in_len=40,include_hour=True,lr=0.0000,normalize=False,out_len=10    </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2671836</td><td>87.3336672782898  </td><td>22.088995933532715  </td><td>22.088995933532715</td><td>22.088995933532715</td><td style=\"text-align: right;\"> 1689062209</td><td>0                        </td><td>                 </td><td>1                   </td><td>26bb9eb6  </td><td>0.0036773681640625   </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_2733401d</td><td>2023-07-11_07-57-56</td><td>      </td><td>                </td><td>f6bbb8cf8f1b4b3fa3ef248b87a4a20d</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680318</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062276</td><td>                         </td><td>                 </td><td>                    </td><td>2733401d  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_276e3911</td><td>2023-07-11_07-55-10</td><td>      </td><td>                </td><td>45a0d3747e1d415e99ab00a2a1c1e631</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2665279</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062110</td><td>                         </td><td>                 </td><td>                    </td><td>276e3911  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_2ab74c7e</td><td>2023-07-11_07-58-27</td><td>      </td><td>                </td><td>1a0aecf6042b4107ba9ab463939aaea4</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2685751</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062307</td><td>                         </td><td>                 </td><td>                    </td><td>2ab74c7e  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_324eaaa6</td><td>2023-07-11_07-57-22</td><td>      </td><td>                </td><td>4de17bc08ce04de49916f40ddd9ea74c</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2675634</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062242</td><td>                         </td><td>                 </td><td>                    </td><td>324eaaa6  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_3374ed88</td><td>2023-07-11_07-58-09</td><td>      </td><td>                </td><td>d13ae5d3e16f486ba65ff1c5ad5dfaaf</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682178</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062289</td><td>                         </td><td>                 </td><td>                    </td><td>3374ed88  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_397c9989</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>74ea1d0c2af648da95a9f0e0a49b98f7</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678787</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>397c9989  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_3afa1bde</td><td>2023-07-11_07-55-44</td><td>      </td><td>                </td><td>527c832f27254adbb3d00e086cbc841d</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2667086</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062144</td><td>                         </td><td>                 </td><td>                    </td><td>3afa1bde  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_3c68e519</td><td>2023-07-11_07-56-32</td><td>True  </td><td>                </td><td>bc5bcf4d494b4ca984a7fe078355f7b4</td><td>27_batch_size=256,const_init=True,in_len=160,include_hour=False,lr=0.0092,normalize=False,out_len=1  </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2670113</td><td>174.30227994918823</td><td>25.187639236450195  </td><td>25.187639236450195</td><td>25.187639236450195</td><td style=\"text-align: right;\"> 1689062192</td><td>0                        </td><td>                 </td><td>1                   </td><td>3c68e519  </td><td>0.0030875205993652344</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_3dd25a1d</td><td>2023-07-11_07-58-28</td><td>      </td><td>                </td><td>d2b67f0b33bc423b89990694d42ce4f2</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2686307</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062308</td><td>                         </td><td>                 </td><td>                    </td><td>3dd25a1d  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_4051ff4c</td><td>2023-07-11_07-57-11</td><td>      </td><td>                </td><td>e7595f71a24e41ad80087b041dd3a118</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2674689</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062231</td><td>                         </td><td>                 </td><td>                    </td><td>4051ff4c  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_45b35851</td><td>2023-07-11_07-57-03</td><td>      </td><td>                </td><td>a5c8913cdad34c4db3511282b30885b9</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2673910</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062223</td><td>                         </td><td>                 </td><td>                    </td><td>45b35851  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_484e555f</td><td>2023-07-11_07-57-49</td><td>      </td><td>                </td><td>86987b39b6fe4907a1443748c4e11a78</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680055</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062269</td><td>                         </td><td>                 </td><td>                    </td><td>484e555f  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_4acdf74f</td><td>2023-07-11_07-55-33</td><td>True  </td><td>                </td><td>327ee126ca964943ad3ba99faf896074</td><td>13_batch_size=128,const_init=False,in_len=107,include_hour=False,lr=0.0002,normalize=False,out_len=21</td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2663300</td><td>73.27857613563538 </td><td>50.88734698295593   </td><td>50.88734698295593 </td><td>50.88734698295593 </td><td style=\"text-align: right;\"> 1689062133</td><td>0                        </td><td>                 </td><td>1                   </td><td>4acdf74f  </td><td>0.004087924957275391 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_51e32119</td><td>2023-07-11_07-58-19</td><td>      </td><td>                </td><td>772aed709fe7493eaa8242aaf64842d9</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2684289</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062299</td><td>                         </td><td>                 </td><td>                    </td><td>51e32119  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_52883244</td><td>2023-07-11_07-55-31</td><td>True  </td><td>                </td><td>9b2c43b834914022b6db77dc6a10d302</td><td>11_batch_size=16,const_init=True,in_len=141,include_hour=False,lr=0.0036,normalize=False,out_len=17  </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2662821</td><td>165.0952696800232 </td><td>50.47370219230652   </td><td>50.47370219230652 </td><td>50.47370219230652 </td><td style=\"text-align: right;\"> 1689062131</td><td>0                        </td><td>                 </td><td>1                   </td><td>52883244  </td><td>0.004124164581298828 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_547038ab</td><td>2023-07-11_07-57-32</td><td>      </td><td>                </td><td>54609dc087cd428fb79aa9841b6256e9</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2676966</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062252</td><td>                         </td><td>                 </td><td>                    </td><td>547038ab  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5477d387</td><td>2023-07-11_07-57-56</td><td>      </td><td>                </td><td>a46d27974a7349d292c79a3b8f4defbc</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680320</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062276</td><td>                         </td><td>                 </td><td>                    </td><td>5477d387  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_54eb5a92</td><td>2023-07-11_07-57-32</td><td>      </td><td>                </td><td>8b239b2b90c8427b9efbc6b2b53a5e05</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2677069</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062252</td><td>                         </td><td>                 </td><td>                    </td><td>54eb5a92  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_552f986b</td><td>2023-07-11_07-58-27</td><td>      </td><td>                </td><td>c104e253074a48728e647ec4ee449f8e</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2686364</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062307</td><td>                         </td><td>                 </td><td>                    </td><td>552f986b  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_581842e1</td><td>2023-07-11_07-57-32</td><td>      </td><td>                </td><td>ee3554ad3f7246ce9e550361d53c06b0</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2676968</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062252</td><td>                         </td><td>                 </td><td>                    </td><td>581842e1  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5b604c4e</td><td>2023-07-11_07-57-32</td><td>      </td><td>                </td><td>d0ab6ac3347f435fb352ba1faa09aa0a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2676970</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062252</td><td>                         </td><td>                 </td><td>                    </td><td>5b604c4e  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5c7a2019</td><td>2023-07-11_07-56-54</td><td>      </td><td>                </td><td>4e1bfeee439645029a91b6fd71a881ba</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2673285</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062214</td><td>                         </td><td>                 </td><td>                    </td><td>5c7a2019  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5e6cec7e</td><td>2023-07-11_07-57-13</td><td>      </td><td>                </td><td>84018585a60b45eabb466f590e9fbd82</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2674851</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062233</td><td>                         </td><td>                 </td><td>                    </td><td>5e6cec7e  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5f17d49b</td><td>2023-07-11_07-55-58</td><td>      </td><td>                </td><td>2b09ea98931545999a563676203fff5d</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2668831</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062158</td><td>                         </td><td>                 </td><td>                    </td><td>5f17d49b  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_5f7bc3df</td><td>2023-07-11_07-58-21</td><td>      </td><td>                </td><td>f7b03fce916442519406f049099e580a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2684740</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062301</td><td>                         </td><td>                 </td><td>                    </td><td>5f7bc3df  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_6d368162</td><td>2023-07-11_07-57-23</td><td>      </td><td>                </td><td>3de3972784f34381bef730953dd94e53</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2676260</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062243</td><td>                         </td><td>                 </td><td>                    </td><td>6d368162  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_6e090e40</td><td>2023-07-11_07-56-19</td><td>      </td><td>                </td><td>accbf51d477d4a00be28187bd4f173fe</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2671273</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062179</td><td>                         </td><td>                 </td><td>                    </td><td>6e090e40  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_6ea47567</td><td>2023-07-11_07-58-09</td><td>      </td><td>                </td><td>fce77cba0dd4452780d7e84418618aff</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682182</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062289</td><td>                         </td><td>                 </td><td>                    </td><td>6ea47567  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_71e0cc0c</td><td>2023-07-11_07-58-18</td><td>      </td><td>                </td><td>f4fa98b6370f4b29be15379a8a3f4ea1</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683803</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062298</td><td>                         </td><td>                 </td><td>                    </td><td>71e0cc0c  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_7751e270</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>880ab33b55c9497d87bc1cc6a870016d</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678685</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>7751e270  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_7f155dc4</td><td>2023-07-11_07-58-09</td><td>      </td><td>                </td><td>0624f512b1304a7996fe15ef9626d4fc</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682314</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062289</td><td>                         </td><td>                 </td><td>                    </td><td>7f155dc4  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_7ffb15d5</td><td>2023-07-11_07-57-03</td><td>      </td><td>                </td><td>df24aa34cc3f4f27b979edbe3053ed7f</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2673908</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062223</td><td>                         </td><td>                 </td><td>                    </td><td>7ffb15d5  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_83795140</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>3806a12756d44b9090ece85543a6a0b1</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678738</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>83795140  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_83e99a87</td><td>2023-07-11_07-58-09</td><td>      </td><td>                </td><td>d7c4c3a0d89c443e9e85d0cf9f175581</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682186</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062289</td><td>                         </td><td>                 </td><td>                    </td><td>83e99a87  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_84822c97</td><td>2023-07-11_07-57-13</td><td>      </td><td>                </td><td>64b7ea49ccde4112ad9874d9a80f3277</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2675166</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062233</td><td>                         </td><td>                 </td><td>                    </td><td>84822c97  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_85c62b7a</td><td>2023-07-11_07-54-54</td><td>True  </td><td>                </td><td>13c3334811264f3c9d7900f3446ea2fc</td><td>8_batch_size=128,const_init=False,in_len=154,include_hour=False,lr=0.0001,normalize=False,out_len=20 </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660923</td><td>108.20406675338745</td><td>21.646451234817505  </td><td>21.646451234817505</td><td>21.646451234817505</td><td style=\"text-align: right;\"> 1689062094</td><td>0                        </td><td>                 </td><td>1                   </td><td>85c62b7a  </td><td>0.004614591598510742 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_89536f7c</td><td>2023-07-11_07-55-50</td><td>True  </td><td>                </td><td>b08100fc43df45d8bb350a369bf4456c</td><td>3_batch_size=32,const_init=True,in_len=89,include_hour=False,lr=0.0143,normalize=False,out_len=15    </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660277</td><td>166.81092977523804</td><td>84.24657654762268   </td><td>84.24657654762268 </td><td>84.24657654762268 </td><td style=\"text-align: right;\"> 1689062150</td><td>0                        </td><td>                 </td><td>1                   </td><td>89536f7c  </td><td>0.0029714107513427734</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_8ba05c9a</td><td>2023-07-11_07-56-10</td><td>      </td><td>                </td><td>b2b75c99a4bf4995b6b736124ea2bc0a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2670503</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062170</td><td>                         </td><td>                 </td><td>                    </td><td>8ba05c9a  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_8c2e59fb</td><td>2023-07-11_07-58-27</td><td>      </td><td>                </td><td>6ec9da1cfb504d58bd221d21f89d89bc</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2685755</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062307</td><td>                         </td><td>                 </td><td>                    </td><td>8c2e59fb  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_92a8b3ee</td><td>2023-07-11_07-54-32</td><td>      </td><td>                </td><td>b11fc0a955da4146bd4a25689a97bd2c</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660916</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062072</td><td>                         </td><td>                 </td><td>                    </td><td>92a8b3ee  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_99b79f5a</td><td>2023-07-11_07-57-55</td><td>      </td><td>                </td><td>eeb00e2e1a4c470dab7391ac2a318518</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680373</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062275</td><td>                         </td><td>                 </td><td>                    </td><td>99b79f5a  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_9b0657d4</td><td>2023-07-11_07-58-09</td><td>      </td><td>                </td><td>953f676801144b72b0ae365a7496dd86</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682184</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062289</td><td>                         </td><td>                 </td><td>                    </td><td>9b0657d4  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_9c14ec7b</td><td>2023-07-11_07-58-18</td><td>      </td><td>                </td><td>9984d0b0dc224c8d83d9343aefae5095</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683807</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062298</td><td>                         </td><td>                 </td><td>                    </td><td>9c14ec7b  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_a4e88e39</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>7ad2c2fe61024346ad7bdf89d177f968</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678789</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>a4e88e39  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_a7d7c4b8</td><td>2023-07-11_07-58-30</td><td>      </td><td>                </td><td>c66db8f37ae046eca13fe1dae624744f</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2686802</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062310</td><td>                         </td><td>                 </td><td>                    </td><td>a7d7c4b8  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_ac0a4644</td><td>2023-07-11_07-57-08</td><td>True  </td><td>                </td><td>d31523064359417ca12afe2af1760d34</td><td>23_batch_size=16,const_init=True,in_len=148,include_hour=False,lr=0.0000,normalize=False,out_len=4   </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2668475</td><td>96.68065309524536 </td><td>70.20492577552795   </td><td>70.20492577552795 </td><td>70.20492577552795 </td><td style=\"text-align: right;\"> 1689062228</td><td>0                        </td><td>                 </td><td>1                   </td><td>ac0a4644  </td><td>0.003229379653930664 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_ad8e1ac8</td><td>2023-07-11_07-57-36</td><td>True  </td><td>                </td><td>2f4b94303b0945e7b39010ef4e262f81</td><td>18_batch_size=256,const_init=True,in_len=80,include_hour=False,lr=0.0000,normalize=False,out_len=2   </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2666083</td><td>81.73577785491943 </td><td>127.80424857139587  </td><td>127.80424857139587</td><td>127.80424857139587</td><td style=\"text-align: right;\"> 1689062256</td><td>0                        </td><td>                 </td><td>1                   </td><td>ad8e1ac8  </td><td>0.0038955211639404297</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_ae0acbfd</td><td>2023-07-11_07-57-22</td><td>      </td><td>                </td><td>28fe95f99ed746d993e4f23806a3f9a4</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2675687</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062242</td><td>                         </td><td>                 </td><td>                    </td><td>ae0acbfd  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_af69c24b</td><td>2023-07-11_07-58-10</td><td>      </td><td>                </td><td>ac156abefe70481d96bb6f7ab0c19cd6</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2682236</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062290</td><td>                         </td><td>                 </td><td>                    </td><td>af69c24b  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_afb75e49</td><td>2023-07-11_07-55-51</td><td>      </td><td>                </td><td>ff4b9c16b0894343a662782ec95e563f</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2667996</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062151</td><td>                         </td><td>                 </td><td>                    </td><td>afb75e49  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_b0f3656a</td><td>2023-07-11_07-54-20</td><td>      </td><td>                </td><td>28c08ba7b19e4e5389400d8012cf061e</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2659835</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062060</td><td>                         </td><td>                 </td><td>                    </td><td>b0f3656a  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_ba05bef5</td><td>2023-07-11_07-56-12</td><td>True  </td><td>                </td><td>b0355c99fffa46b287e4fe837f3b6183</td><td>15_batch_size=128,const_init=False,in_len=114,include_hour=True,lr=0.0007,normalize=False,out_len=15 </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2664804</td><td>68.18698644638062 </td><td>69.23792958259583   </td><td>69.23792958259583 </td><td>69.23792958259583 </td><td style=\"text-align: right;\"> 1689062172</td><td>0                        </td><td>                 </td><td>1                   </td><td>ba05bef5  </td><td>0.0033156871795654297</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_bc8a869b</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>4c6235dc070d48dca2a8dafba12f7525</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678687</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>bc8a869b  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_c6db46a9</td><td>2023-07-11_07-55-00</td><td>      </td><td>                </td><td>fc6f97385c5d4ba3a05d6ca020ffe186</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2664634</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062100</td><td>                         </td><td>                 </td><td>                    </td><td>c6db46a9  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_c9b28f1d</td><td>2023-07-11_07-56-47</td><td>True  </td><td>                </td><td>bcaffc61efed4858836493d563daa0d0</td><td>28_batch_size=128,const_init=True,in_len=152,include_hour=False,lr=0.0003,normalize=False,out_len=5  </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2670276</td><td>82.65145421028137 </td><td>38.7388219833374    </td><td>38.7388219833374  </td><td>38.7388219833374  </td><td style=\"text-align: right;\"> 1689062207</td><td>0                        </td><td>                 </td><td>1                   </td><td>c9b28f1d  </td><td>0.0038042068481445312</td></tr>\n",
       "<tr><td>build_fit_nlinear_model_cb252c9a</td><td>2023-07-11_07-58-34</td><td>True  </td><td>                </td><td>205352b17f1243eb94a79eda15778d83</td><td>1_batch_size=64,const_init=False,in_len=64,include_hour=False,lr=0.0001,normalize=False,out_len=22   </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2659586</td><td>22.97404855489731 </td><td>258.65275168418884  </td><td>258.65275168418884</td><td>258.65275168418884</td><td style=\"text-align: right;\"> 1689062314</td><td>0                        </td><td>                 </td><td>1                   </td><td>cb252c9a  </td><td>0.003572702407836914 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_cb9805fc</td><td>2023-07-11_07-57-44</td><td>      </td><td>                </td><td>b4698f1f7b944cf3a6b557d4acecc258</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2678689</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062264</td><td>                         </td><td>                 </td><td>                    </td><td>cb9805fc  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_cd75ee08</td><td>2023-07-11_07-58-18</td><td>      </td><td>                </td><td>ba5060bddae544dea5d8889c7870e74a</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683805</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062298</td><td>                         </td><td>                 </td><td>                    </td><td>cd75ee08  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_d036aeba</td><td>2023-07-11_07-55-38</td><td>      </td><td>                </td><td>f30b430b9ab44468ac42be7fc887b94e</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2666500</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062138</td><td>                         </td><td>                 </td><td>                    </td><td>d036aeba  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_d26c61b8</td><td>2023-07-11_07-58-18</td><td>      </td><td>                </td><td>3fd3c633f6a24c4da55322a51bda16e2</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683856</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062298</td><td>                         </td><td>                 </td><td>                    </td><td>d26c61b8  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_d9aa9748</td><td>2023-07-11_07-58-03</td><td>      </td><td>                </td><td>51fbbcc96a3a4f7ab2ed6e92ba9752e9</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2681858</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062283</td><td>                         </td><td>                 </td><td>                    </td><td>d9aa9748  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_da04cd3f</td><td>2023-07-11_07-57-56</td><td>      </td><td>                </td><td>6f039bd2c7d04e2287b1c406efeaf4d9</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680422</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062276</td><td>                         </td><td>                 </td><td>                    </td><td>da04cd3f  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_da1ad403</td><td>2023-07-11_07-58-27</td><td>      </td><td>                </td><td>0889183fe7734cc48f2f501518192e41</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2685757</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062307</td><td>                         </td><td>                 </td><td>                    </td><td>da1ad403  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_de4e68e5</td><td>2023-07-11_07-57-29</td><td>True  </td><td>                </td><td>eb9b5fb056de43f78e8c21c81ee32aec</td><td>35_batch_size=64,const_init=False,in_len=159,include_hour=False,lr=0.0001,normalize=False,out_len=13 </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2672702</td><td>146.9861388206482 </td><td>41.91266918182373   </td><td>41.91266918182373 </td><td>41.91266918182373 </td><td style=\"text-align: right;\"> 1689062249</td><td>0                        </td><td>                 </td><td>1                   </td><td>de4e68e5  </td><td>0.003229379653930664 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_def6272f</td><td>2023-07-11_07-55-40</td><td>True  </td><td>                </td><td>aeb14801bf854668b55d6def92f7acc1</td><td>12_batch_size=32,const_init=True,in_len=54,include_hour=False,lr=0.0001,normalize=False,out_len=6    </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2662823</td><td>92.29645133018494 </td><td>58.53361201286316   </td><td>58.53361201286316 </td><td>58.53361201286316 </td><td style=\"text-align: right;\"> 1689062140</td><td>0                        </td><td>                 </td><td>1                   </td><td>def6272f  </td><td>0.004075288772583008 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_e072d3a5</td><td>2023-07-11_07-57-12</td><td>      </td><td>                </td><td>28a57d8b684348258d2b39e808867937</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2674849</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062232</td><td>                         </td><td>                 </td><td>                    </td><td>e072d3a5  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_e128fbd6</td><td>2023-07-11_07-57-56</td><td>      </td><td>                </td><td>de46bff63fff4d87a198487c7d372287</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680322</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062276</td><td>                         </td><td>                 </td><td>                    </td><td>e128fbd6  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_e3923dbc</td><td>2023-07-11_07-58-18</td><td>      </td><td>                </td><td>b926d7af79a743778541afab89389071</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2683905</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062298</td><td>                         </td><td>                 </td><td>                    </td><td>e3923dbc  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_e6bc2e6c</td><td>2023-07-11_07-54-32</td><td>      </td><td>                </td><td>535f6ae154694538877ab927eb767f50</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660919</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062072</td><td>                         </td><td>                 </td><td>                    </td><td>e6bc2e6c  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_e84d3c06</td><td>2023-07-11_07-58-27</td><td>      </td><td>                </td><td>f9576eeefc3c46dba73f41b8fbab007f</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2685753</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062307</td><td>                         </td><td>                 </td><td>                    </td><td>e84d3c06  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_eadf06e9</td><td>2023-07-11_07-57-55</td><td>      </td><td>                </td><td>1357b77598d444cda1050e99afc385ba</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2680371</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062275</td><td>                         </td><td>                 </td><td>                    </td><td>eadf06e9  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_f25d8dd7</td><td>2023-07-11_07-55-58</td><td>      </td><td>                </td><td>a9fd5bf9cd2e447982a927bd440f32dc</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2668478</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062158</td><td>                         </td><td>                 </td><td>                    </td><td>f25d8dd7  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_f53eee60</td><td>2023-07-11_07-55-42</td><td>True  </td><td>                </td><td>70f730cff4024622add748c79a5c358a</td><td>10_batch_size=32,const_init=False,in_len=49,include_hour=True,lr=0.0154,normalize=False,out_len=23   </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2662819</td><td>189.46653604507446</td><td>60.65873074531555   </td><td>60.65873074531555 </td><td>60.65873074531555 </td><td style=\"text-align: right;\"> 1689062142</td><td>0                        </td><td>                 </td><td>1                   </td><td>f53eee60  </td><td>0.011582612991333008 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_f58b4366</td><td>2023-07-11_07-55-18</td><td>      </td><td>                </td><td>5d9c511f1f8148e88f9243a6403d9107</td><td>                                                                                                     </td><td>ip-172-31-10-87</td><td>                          </td><td>172.31.10.87</td><td style=\"text-align: right;\">2665601</td><td>                  </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1689062118</td><td>                         </td><td>                 </td><td>                    </td><td>f58b4366  </td><td>                     </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_f7886908</td><td>2023-07-11_07-54-55</td><td>True  </td><td>                </td><td>b1612249dc614ed08c14ddeb5b2a0530</td><td>7_batch_size=128,const_init=True,in_len=117,include_hour=True,lr=0.0347,normalize=False,out_len=4    </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2660921</td><td>197.14208841323853</td><td>23.25703716278076   </td><td>23.25703716278076 </td><td>23.25703716278076 </td><td style=\"text-align: right;\"> 1689062095</td><td>0                        </td><td>                 </td><td>1                   </td><td>f7886908  </td><td>0.003682851791381836 </td></tr>\n",
       "<tr><td>build_fit_nlinear_model_feb74060</td><td>2023-07-11_07-57-18</td><td>True  </td><td>                </td><td>7bb84e2668e64193acdaf9b6929f5b45</td><td>33_batch_size=128,const_init=True,in_len=146,include_hour=True,lr=0.0001,normalize=False,out_len=9   </td><td>ip-172-31-10-87</td><td>1                         </td><td>172.31.10.87</td><td style=\"text-align: right;\">2671993</td><td>50.491225719451904</td><td>50.69149994850159   </td><td>50.69149994850159 </td><td>50.69149994850159 </td><td style=\"text-align: right;\"> 1689062238</td><td>0                        </td><td>                 </td><td>1                   </td><td>feb74060  </td><td>0.004072904586791992 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:26 (running for 00:00:15.76)\n",
      "Memory usage on this node: 89.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 10.0/48 CPUs, 0.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 4/100 (1 ERROR, 1 PENDING, 2 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "| build_fit_nlinear_model_12f2a79e | PENDING  |                      |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR    | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "Number of errored trials: 1\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 3 | layer          | Linear           | 2.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 2.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 2.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m 0.011     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:31 (running for 00:00:20.88)\n",
      "Memory usage on this node: 91.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 10/100 (1 ERROR, 1 PENDING, 8 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "| build_fit_nlinear_model_12f2a79e | RUNNING  | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |\n",
      "| build_fit_nlinear_model_92a8b3ee | RUNNING  | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |\n",
      "| build_fit_nlinear_model_e6bc2e6c | RUNNING  | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |\n",
      "| build_fit_nlinear_model_f7886908 | RUNNING  | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |\n",
      "| build_fit_nlinear_model_85c62b7a | RUNNING  | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | RUNNING  | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |\n",
      "| build_fit_nlinear_model_f53eee60 | PENDING  |                      |       49 |        23 | False       | False        | 0.015403    | True           |           32 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR    | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "Number of errored trials: 1\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 3 | layer          | Linear           | 1.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660913)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 3 | layer          | Linear           | 536   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 538       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 538       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660916)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 3 | layer          | Linear           | 11.7 K\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 11.7 K    Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 11.7 K    Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660919)\u001b[0m 0.047     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 3 | layer          | Linear           | 6.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 6.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 6.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m 0.025     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 3 | layer          | Linear           | 1.9 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 1.9 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 1.9 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m 0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 3 | layer          | Linear           | 401   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 405       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 405       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660925)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:36 (running for 00:00:26.35)\n",
      "Memory usage on this node: 93.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 13/100 (5 ERROR, 8 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "| build_fit_nlinear_model_f7886908 | RUNNING  | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |\n",
      "| build_fit_nlinear_model_85c62b7a | RUNNING  | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING  | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING  | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING  | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING  | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR    | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR    | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR    | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR    | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR    | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "Number of errored trials: 5\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 3 | layer          | Linear           | 4.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 4.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 4.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 3 | layer          | Linear           | 654   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 656       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 656       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 3 | layer          | Linear           | 4.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 4.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 4.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 3 | layer          | Linear           | 4.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 4.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 4.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:48 (running for 00:00:37.77)\n",
      "Memory usage on this node: 99.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 14/100 (5 ERROR, 1 PENDING, 8 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "| build_fit_nlinear_model_f7886908 | RUNNING  | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |\n",
      "| build_fit_nlinear_model_85c62b7a | RUNNING  | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING  | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING  | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING  | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING  | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |\n",
      "| build_fit_nlinear_model_c6db46a9 | PENDING  |                      |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR    | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR    | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR    | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR    | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR    | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "Number of errored trials: 5\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-07-11 07:54:53 (running for 00:00:42.78)\n",
      "Memory usage on this node: 102.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 14/100 (5 ERROR, 1 PENDING, 8 RUNNING)\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "| Trial name                       | status   | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |\n",
      "|----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING  | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING  | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |\n",
      "| build_fit_nlinear_model_f7886908 | RUNNING  | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |\n",
      "| build_fit_nlinear_model_85c62b7a | RUNNING  | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING  | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING  | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING  | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING  | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |\n",
      "| build_fit_nlinear_model_c6db46a9 | PENDING  |                      |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR    | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR    | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR    | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR    | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR    | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |\n",
      "+----------------------------------+----------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+\n",
      "Number of errored trials: 5\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660923)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.01it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660921)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.48it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 3 | layer          | Linear           | 3.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 3.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 3.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664634)\u001b[0m 0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:01 (running for 00:00:51.37)\n",
      "Memory usage on this node: 100.2/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 85c62b7a with q_smape=108.20406675338745 and parameters={'in_len': 154, 'out_len': 20, 'normalize': False, 'const_init': False, 'lr': 9.403939261939506e-05, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 16/100 (5 ERROR, 1 PENDING, 8 RUNNING, 2 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING    | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING    | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | RUNNING    | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_276e3911 | PENDING    |                      |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |   197.142 |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |   108.204 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "Number of errored trials: 5\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 3 | layer          | Linear           | 6.9 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 6.9 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 6.9 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m 0.027     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:09 (running for 00:00:59.36)\n",
      "Memory usage on this node: 103.6/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 85c62b7a with q_smape=108.20406675338745 and parameters={'in_len': 154, 'out_len': 20, 'normalize': False, 'const_init': False, 'lr': 9.403939261939506e-05, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 17/100 (6 ERROR, 1 PENDING, 8 RUNNING, 2 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING    | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING    | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_276e3911 | RUNNING    | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f58b4366 | PENDING    |                      |       88 |         1 | True        | True         | 3.6854e-05  | True           |           32 |           |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |   197.142 |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |   108.204 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "Number of errored trials: 6\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 3 | layer          | Linear           | 2.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 2.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 2.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665279)\u001b[0m 0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:17 (running for 00:01:07.37)\n",
      "Memory usage on this node: 101.8/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 85c62b7a with q_smape=108.20406675338745 and parameters={'in_len': 154, 'out_len': 20, 'normalize': False, 'const_init': False, 'lr': 9.403939261939506e-05, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 18/100 (7 ERROR, 1 PENDING, 8 RUNNING, 2 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING    | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING    | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_f58b4366 | RUNNING    | 172.31.10.87:2665601 |       88 |         1 | True        | True         | 3.6854e-05  | True           |           32 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | PENDING    |                      |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |   197.142 |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |   108.204 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "Number of errored trials: 7\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 3 | layer          | Linear           | 353   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 357       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 357       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2665601)\u001b[0m 0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:27 (running for 00:01:17.37)\n",
      "Memory usage on this node: 103.7/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 85c62b7a with q_smape=108.20406675338745 and parameters={'in_len': 154, 'out_len': 20, 'normalize': False, 'const_init': False, 'lr': 9.403939261939506e-05, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 19/100 (8 ERROR, 1 PENDING, 8 RUNNING, 2 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_52883244 | RUNNING    | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING    | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_d036aeba | PENDING    |                      |      158 |        22 | True        | True         | 0.00020355  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |   197.142 |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |   108.204 |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f58b4366 | ERROR      | 172.31.10.87:2665601 |       88 |         1 | True        | True         | 3.6854e-05  | True           |           32 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "Number of errored trials: 8\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 3 | layer          | Linear           | 322   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 324       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 324       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.46it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662821)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.01it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 251.43it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2663300)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:33 (running for 00:01:23.66)\n",
      "Memory usage on this node: 101.5/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 20/100 (8 ERROR, 1 PENDING, 8 RUNNING, 3 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | RUNNING    | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_d036aeba | RUNNING    | 172.31.10.87:2666500 |      158 |        22 | True        | True         | 0.00020355  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | PENDING    |                      |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_f58b4366 | ERROR      | 172.31.10.87:2665601 |       88 |         1 | True        | True         | 3.6854e-05  | True           |           32 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "Number of errored trials: 8\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 3 | layer          | Linear           | 13.9 K\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 13.9 K    Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 13.9 K    Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666500)\u001b[0m 0.056     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662823)\u001b[0m \r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.58it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2662819)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.31it/s]\n",
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:40 (running for 00:01:29.92)\n",
      "Memory usage on this node: 96.6/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 21/100 (8 ERROR, 1 PENDING, 8 RUNNING, 4 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_3afa1bde | RUNNING    | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_d036aeba | RUNNING    | 172.31.10.87:2666500 |      158 |        22 | True        | True         | 0.00020355  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_def6272f | RUNNING    | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | RUNNING    | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |           |\n",
      "| build_fit_nlinear_model_afb75e49 | PENDING    |                      |      152 |         8 | True        | False        | 0.0112284   | False          |          256 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_f58b4366 | ERROR      | 172.31.10.87:2665601 |       88 |         1 | True        | True         | 3.6854e-05  | True           |           32 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 1 more trials not shown ()\n",
      "Number of errored trials: 8\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 3 | layer          | Linear           | 233   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 237       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 237       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667086)\u001b[0m 0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.34it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2660277)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:46 (running for 00:01:36.36)\n",
      "Memory usage on this node: 92.7/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 30.0/48 CPUs, 2.4/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 21/100 (9 ERROR, 6 RUNNING, 6 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_3afa1bde | RUNNING    | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_afb75e49 | RUNNING    | 172.31.10.87:2667996 |      152 |         8 | True        | False        | 0.0112284   | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_d036aeba | ERROR      | 172.31.10.87:2666500 |      158 |        22 | True        | True         | 0.00020355  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_e6bc2e6c | ERROR      | 172.31.10.87:2660919 |      139 |        21 | True        | False        | 1.19307e-05 | True           |          256 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 1 more trials not shown (1 ERROR)\n",
      "Number of errored trials: 9\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:55:51 (running for 00:01:41.70)\n",
      "Memory usage on this node: 94.0/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 25.0/48 CPUs, 2.0/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 22/100 (10 ERROR, 1 PENDING, 5 RUNNING, 6 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_89536f7c | RUNNING    | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_afb75e49 | RUNNING    | 172.31.10.87:2667996 |      152 |         8 | True        | False        | 0.0112284   | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | PENDING    |                      |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_c6db46a9 | ERROR      | 172.31.10.87:2664634 |      146 |        12 | True        | True         | 3.49909e-05 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_d036aeba | ERROR      | 172.31.10.87:2666500 |      158 |        22 | True        | True         | 0.00020355  | True           |          256 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 2 more trials not shown (2 ERROR)\n",
      "Number of errored trials: 10\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 3 | layer          | Linear           | 2.4 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 2.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 2.4 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2667996)\u001b[0m 0.010     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 3 | layer          | Linear           | 1.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 1.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 1.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m 0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 3 | layer          | Linear           | 5.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 5.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 5.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668478)\u001b[0m 0.023     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 3 | layer          | Linear           | 8.4 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 8.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 8.4 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m 0.034     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 3 | layer          | Linear           | 9.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 9.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 9.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668831)\u001b[0m 0.039     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:00 (running for 00:01:50.38)\n",
      "Memory usage on this node: 96.5/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 27/100 (11 ERROR, 1 PENDING, 8 RUNNING, 7 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | RUNNING    | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | RUNNING    | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | PENDING    |                      |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_afb75e49 | ERROR      | 172.31.10.87:2667996 |      152 |         8 | True        | False        | 0.0112284   | False          |          256 |           |\n",
      "| build_fit_nlinear_model_b0f3656a | ERROR      | 172.31.10.87:2659835 |       50 |        22 | True        | False        | 0.000369927 | False          |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 7 more trials not shown (1 RUNNING, 4 ERROR)\n",
      "Number of errored trials: 11\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 3 | layer          | Linear           | 594   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 598       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 598       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2669339)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 3 | layer          | Linear           | 321   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 323       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 323       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m 0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 3 | layer          | Linear           | 1.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 1.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 1.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:09 (running for 00:01:59.39)\n",
      "Memory usage on this node: 100.0/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: 4acdf74f with q_smape=73.27857613563538 and parameters={'in_len': 107, 'out_len': 21, 'normalize': False, 'const_init': False, 'lr': 0.000176996078925303, 'include_hour': False, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 30/100 (14 ERROR, 1 PENDING, 8 RUNNING, 7 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | RUNNING    | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |           |\n",
      "| build_fit_nlinear_model_8ba05c9a | RUNNING    | 172.31.10.87:2670503 |      153 |         9 | True        | False        | 0.00431309  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ba05bef5 | RUNNING    | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | PENDING    |                      |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_f7886908 | TERMINATED | 172.31.10.87:2660921 |      117 |         4 | False       | True         | 0.0346919   | True           |          128 |  197.142  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | ERROR      | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_92a8b3ee | ERROR      | 172.31.10.87:2660916 |       33 |         8 | True        | False        | 9.55643e-05 | False          |          256 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 10 more trials not shown (1 RUNNING, 7 ERROR)\n",
      "Number of errored trials: 14\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 3 | layer          | Linear           | 2.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 2.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 2.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670503)\u001b[0m 0.011     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2664804)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 250.80it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:18 (running for 00:02:08.38)\n",
      "Memory usage on this node: 97.2/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 32/100 (15 ERROR, 1 PENDING, 8 RUNNING, 8 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | RUNNING    | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | RUNNING    | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |           |\n",
      "| build_fit_nlinear_model_6e090e40 | RUNNING    | 172.31.10.87:2671273 |      150 |        13 | True        | False        | 0.00655881  | True           |           16 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_26bb9eb6 | PENDING    |                      |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ba05bef5 | TERMINATED | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |   68.187  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | ERROR      | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_8ba05c9a | ERROR      | 172.31.10.87:2670503 |      153 |         9 | True        | False        | 0.00431309  | False          |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 12 more trials not shown (1 RUNNING, 1 TERMINATED, 8 ERROR)\n",
      "Number of errored trials: 15\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 3 | layer          | Linear           | 2.9 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 2.9 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 2.9 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671114)\u001b[0m 0.011     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 3 | layer          | Linear           | 7.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 7.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 7.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671273)\u001b[0m 0.031     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:27 (running for 00:02:17.39)\n",
      "Memory usage on this node: 95.7/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 34/100 (17 ERROR, 1 PENDING, 8 RUNNING, 8 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_26bb9eb6 | RUNNING    | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | RUNNING    | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | PENDING    |                      |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ba05bef5 | TERMINATED | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |   68.187  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | ERROR      | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 14 more trials not shown (1 RUNNING, 1 TERMINATED, 10 ERROR)\n",
      "Number of errored trials: 17\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 3 | layer          | Linear           | 1.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 1.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 1.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m 0.006     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 3 | layer          | Linear           | 5.3 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 5.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 5.3 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m 0.021     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:32 (running for 00:02:22.63)\n",
      "Memory usage on this node: 99.1/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 34/100 (17 ERROR, 1 PENDING, 8 RUNNING, 8 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_26bb9eb6 | RUNNING    | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | RUNNING    | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | PENDING    |                      |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ba05bef5 | TERMINATED | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |   68.187  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_f53eee60 | TERMINATED | 172.31.10.87:2662819 |       49 |        23 | False       | False        | 0.015403    | True           |           32 |  189.467  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | ERROR      | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 14 more trials not shown (1 RUNNING, 1 TERMINATED, 10 ERROR)\n",
      "Number of errored trials: 17\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670113)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.67it/s]\n",
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:39 (running for 00:02:29.39)\n",
      "Memory usage on this node: 95.4/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 35/100 (17 ERROR, 1 PENDING, 8 RUNNING, 9 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | RUNNING    | 172.31.10.87:2672409 |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_26bb9eb6 | RUNNING    | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_de4e68e5 | PENDING    |                      |      159 |        13 | False       | False        | 6.06724e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ba05bef5 | TERMINATED | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |   68.187  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_5f17d49b | ERROR      | 172.31.10.87:2668831 |      144 |        17 | True        | False        | 1.44094e-05 | True           |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 15 more trials not shown (1 RUNNING, 2 TERMINATED, 10 ERROR)\n",
      "Number of errored trials: 17\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 3 | layer          | Linear           | 4.0 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 4.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 4.0 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672409)\u001b[0m 0.016     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2670276)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.00it/s]\n",
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:47 (running for 00:02:37.06)\n",
      "Memory usage on this node: 90.8/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 36/100 (18 ERROR, 1 PENDING, 8 RUNNING, 9 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_06c8d9a1 | RUNNING    | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_26bb9eb6 | RUNNING    | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_c9b28f1d | RUNNING    | 172.31.10.87:2670276 |      152 |         5 | False       | True         | 0.000284862 | False          |          128 |   82.6515 |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_de4e68e5 | RUNNING    | 172.31.10.87:2672702 |      159 |        13 | False       | False        | 6.06724e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_1a719bad | PENDING    |                      |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ba05bef5 | TERMINATED | 172.31.10.87:2664804 |      114 |        15 | False       | False        | 0.000651158 | True           |          128 |   68.187  |\n",
      "| build_fit_nlinear_model_def6272f | TERMINATED | 172.31.10.87:2662823 |       54 |         6 | False       | True         | 7.64603e-05 | False          |           32 |   92.2965 |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | ERROR      | 172.31.10.87:2672409 |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 16 more trials not shown (1 RUNNING, 2 TERMINATED, 11 ERROR)\n",
      "Number of errored trials: 18\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.50it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668469)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 3 | layer          | Linear           | 4.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 4.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 4.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m 0.017     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671836)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.91it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('val_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_MeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_SymmetricMeanAbsolutePercentageError', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:56:54 (running for 00:02:44.44)\n",
      "Memory usage on this node: 89.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 39/100 (18 ERROR, 1 PENDING, 8 RUNNING, 12 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_1a719bad | RUNNING    | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1eb26ae5 | RUNNING    | 172.31.10.87:2673283 |       11 |        11 | True        | False        | 1.56264e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_5c7a2019 | RUNNING    | 172.31.10.87:2673285 |       80 |        13 | True        | False        | 0.00117704  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_de4e68e5 | RUNNING    | 172.31.10.87:2672702 |      159 |        13 | False       | False        | 6.06724e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_7ffb15d5 | PENDING    |                      |       81 |        13 | True        | False        | 0.00173024  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | ERROR      | 172.31.10.87:2672409 |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_276e3911 | ERROR      | 172.31.10.87:2665279 |       67 |        19 | True        | True         | 0.0106392   | False          |           32 |           |\n",
      "| build_fit_nlinear_model_3afa1bde | ERROR      | 172.31.10.87:2667086 |       58 |         1 | True        | True         | 7.18452e-05 | True           |           16 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 19 more trials not shown (1 RUNNING, 5 TERMINATED, 11 ERROR)\n",
      "Number of errored trials: 18\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 3 | layer          | Linear           | 1.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 4 | linear_fut_cov | Linear           | 2     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 1.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 1.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673113)\u001b[0m 0.004     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 3 | layer          | Linear           | 495   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 499       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 499       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673283)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 3 | layer          | Linear           | 4.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 4.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 4.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673285)\u001b[0m 0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:03 (running for 00:02:53.40)\n",
      "Memory usage on this node: 89.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 42/100 (21 ERROR, 1 PENDING, 8 RUNNING, 12 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_03542bb7 | RUNNING    | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_45b35851 | RUNNING    | 172.31.10.87:2673910 |       79 |        13 | True        | False        | 0.000817618 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_7ffb15d5 | RUNNING    | 172.31.10.87:2673908 |       81 |        13 | True        | False        | 0.00173024  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ac0a4644 | RUNNING    | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_de4e68e5 | RUNNING    | 172.31.10.87:2672702 |      159 |        13 | False       | False        | 6.06724e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_4051ff4c | PENDING    |                      |       80 |        13 | True        | False        | 0.000863965 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_1eb26ae5 | ERROR      | 172.31.10.87:2673283 |       11 |        11 | True        | False        | 1.56264e-05 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_21ea8994 | ERROR      | 172.31.10.87:2672409 |      142 |        14 | True        | False        | 2.43478e-05 | False          |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 22 more trials not shown (1 RUNNING, 5 TERMINATED, 14 ERROR)\n",
      "Number of errored trials: 21\n",
      "Table truncated to 20 rows (1 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 3 | layer          | Linear           | 4.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 4.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 4.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673910)\u001b[0m 0.017     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 3 | layer          | Linear           | 4.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 4.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 4.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2673908)\u001b[0m 0.017     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 3 | layer          | Linear           | 3.9 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 4.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 4.0 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674221)\u001b[0m 0.016     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2668475)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.26it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 3 | layer          | Linear           | 4.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 4.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 4.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674689)\u001b[0m 0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:13 (running for 00:03:03.40)\n",
      "Memory usage on this node: 89.4/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: ba05bef5 with q_smape=68.18698644638062 and parameters={'in_len': 114, 'out_len': 15, 'normalize': False, 'const_init': False, 'lr': 0.0006511575404038469, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 46/100 (24 ERROR, 1 PENDING, 8 RUNNING, 13 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_4051ff4c | RUNNING    | 172.31.10.87:2674689 |       80 |        13 | True        | False        | 0.000863965 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_5e6cec7e | RUNNING    | 172.31.10.87:2674851 |       82 |        13 | True        | False        | 0.000933425 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_84822c97 | RUNNING    | 172.31.10.87:2675166 |       87 |        13 | True        | False        | 0.000566731 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_de4e68e5 | RUNNING    | 172.31.10.87:2672702 |      159 |        13 | False       | False        | 6.06724e-05 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_e072d3a5 | RUNNING    | 172.31.10.87:2674849 |       79 |        14 | True        | False        | 0.00103596  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_324eaaa6 | PENDING    |                      |       81 |        12 | True        | False        | 0.000544638 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_1eb26ae5 | ERROR      | 172.31.10.87:2673283 |       11 |        11 | True        | False        | 1.56264e-05 | True           |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 26 more trials not shown (1 RUNNING, 6 TERMINATED, 17 ERROR)\n",
      "Number of errored trials: 24\n",
      "Table truncated to 20 rows (4 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 3 | layer          | Linear           | 4.4 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 4.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 4.4 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674849)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 3 | layer          | Linear           | 4.3 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 4.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 4.3 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2674851)\u001b[0m 0.017     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 3 | layer          | Linear           | 4.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 4.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 4.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675166)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m Auto select gpus: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2671993)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.51it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.11it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 3 | layer          | Linear           | 4.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 4.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 4.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675636)\u001b[0m 0.016     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m Auto select gpus: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:23 (running for 00:03:13.40)\n",
      "Memory usage on this node: 86.4/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 51/100 (28 ERROR, 1 PENDING, 8 RUNNING, 14 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_15b489a7 | RUNNING    | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_236b9e67 | RUNNING    | 172.31.10.87:2675638 |       76 |        13 | True        | False        | 0.000797399 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_324eaaa6 | RUNNING    | 172.31.10.87:2675634 |       81 |        12 | True        | False        | 0.000544638 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_6d368162 | RUNNING    | 172.31.10.87:2676260 |       77 |        13 | True        | False        | 0.000937298 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_ae0acbfd | RUNNING    | 172.31.10.87:2675687 |       11 |        13 | True        | False        | 0.00107834  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_547038ab | PENDING    |                      |       14 |        11 | True        | False        | 0.00119634  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_1eb26ae5 | ERROR      | 172.31.10.87:2673283 |       11 |        11 | True        | False        | 1.56264e-05 | True           |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 31 more trials not shown (1 RUNNING, 7 TERMINATED, 21 ERROR)\n",
      "Number of errored trials: 28\n",
      "Table truncated to 20 rows (8 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 3 | layer          | Linear           | 3.9 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 3.9 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 3.9 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675634)\u001b[0m 0.016     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 3 | layer          | Linear           | 585   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 589       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 589       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675687)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 3 | layer          | Linear           | 4.0 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 4.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 4.0 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2675638)\u001b[0m 0.016     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 3 | layer          | Linear           | 4.0 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 4.0 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 4.0 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676260)\u001b[0m 0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.66it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2672702)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:29 (running for 00:03:19.43)\n",
      "Memory usage on this node: 81.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 56/100 (33 ERROR, 1 PENDING, 8 RUNNING, 14 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_21b28051 | RUNNING    | 172.31.10.87:2677019 |        8 |        11 | True        | False        | 0.00112037  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_547038ab | RUNNING    | 172.31.10.87:2676966 |       14 |        11 | True        | False        | 0.00119634  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_54eb5a92 | RUNNING    | 172.31.10.87:2677069 |       80 |        11 | True        | False        | 0.000882448 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_581842e1 | RUNNING    | 172.31.10.87:2676968 |      129 |        11 | True        | False        | 0.000968239 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_5b604c4e | RUNNING    | 172.31.10.87:2676970 |      129 |        11 | True        | False        | 0.000570998 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | PENDING    |                      |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 36 more trials not shown (1 RUNNING, 7 TERMINATED, 26 ERROR)\n",
      "Number of errored trials: 33\n",
      "Table truncated to 20 rows (13 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 3 | layer          | Linear           | 627   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 631       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 631       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676966)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 3 | layer          | Linear           | 363   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 367       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 367       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677019)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 3 | layer          | Linear           | 3.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 3.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 3.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2677069)\u001b[0m 0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 3 | layer          | Linear           | 5.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 5.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 5.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676968)\u001b[0m 0.023     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 3 | layer          | Linear           | 5.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 5.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 5.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2676970)\u001b[0m 0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.27it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2666083)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:35 (running for 00:03:24.77)\n",
      "Memory usage on this node: 87.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 57/100 (34 ERROR, 1 PENDING, 7 RUNNING, 15 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_17cb88ed | RUNNING    | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_21b28051 | RUNNING    | 172.31.10.87:2677019 |        8 |        11 | True        | False        | 0.00112037  | True           |          256 |           |\n",
      "| build_fit_nlinear_model_54eb5a92 | RUNNING    | 172.31.10.87:2677069 |       80 |        11 | True        | False        | 0.000882448 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_581842e1 | RUNNING    | 172.31.10.87:2676968 |      129 |        11 | True        | False        | 0.000968239 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_5b604c4e | RUNNING    | 172.31.10.87:2676970 |      129 |        11 | True        | False        | 0.000570998 | True           |           64 |           |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | RUNNING    | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_7751e270 | PENDING    |                      |      132 |        10 | True        | False        | 0.000827043 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 37 more trials not shown (8 TERMINATED, 27 ERROR)\n",
      "Number of errored trials: 34\n",
      "Table truncated to 20 rows (14 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 3 | layer          | Linear           | 5.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 5.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 5.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678200)\u001b[0m 0.023     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:41 (running for 00:03:30.83)\n",
      "Memory usage on this node: 80.4/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 63/100 (39 ERROR, 1 PENDING, 7 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_397c9989 | RUNNING    | 172.31.10.87:2678787 |      128 |        11 | True        | False        | 0.000985533 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_7751e270 | RUNNING    | 172.31.10.87:2678685 |      132 |        10 | True        | False        | 0.000827043 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_83795140 | RUNNING    | 172.31.10.87:2678738 |      129 |        11 | True        | False        | 0.000808291 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_a4e88e39 | RUNNING    | 172.31.10.87:2678789 |        9 |        11 | True        | False        | 0.00094965  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_bc8a869b | RUNNING    | 172.31.10.87:2678687 |      126 |         9 | True        | False        | 0.00108192  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_cb9805fc | RUNNING    | 172.31.10.87:2678689 |      129 |        10 | True        | False        | 0.00102475  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_484e555f | PENDING    |                      |       11 |         9 | True        | False        | 0.000834312 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 43 more trials not shown (9 TERMINATED, 32 ERROR)\n",
      "Number of errored trials: 39\n",
      "Table truncated to 20 rows (19 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 3 | layer          | Linear           | 4.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 4.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 4.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678687)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 3 | layer          | Linear           | 5.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 5.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 5.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678738)\u001b[0m 0.023     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 3 | layer          | Linear           | 5.3 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 5.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 5.3 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678685)\u001b[0m 0.021     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 3 | layer          | Linear           | 407   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 411       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 411       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678789)\u001b[0m 0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 3 | layer          | Linear           | 5.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 5.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 5.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678787)\u001b[0m 0.023     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 3 | layer          | Linear           | 5.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 5.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 5.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2678689)\u001b[0m 0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:46 (running for 00:03:36.57)\n",
      "Memory usage on this node: 89.0/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 64/100 (40 ERROR, 1 PENDING, 7 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_397c9989 | RUNNING    | 172.31.10.87:2678787 |      128 |        11 | True        | False        | 0.000985533 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_484e555f | RUNNING    | 172.31.10.87:2680055 |       11 |         9 | True        | False        | 0.000834312 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_7751e270 | RUNNING    | 172.31.10.87:2678685 |      132 |        10 | True        | False        | 0.000827043 | True           |          256 |           |\n",
      "| build_fit_nlinear_model_83795140 | RUNNING    | 172.31.10.87:2678738 |      129 |        11 | True        | False        | 0.000808291 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_a4e88e39 | RUNNING    | 172.31.10.87:2678789 |        9 |        11 | True        | False        | 0.00094965  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_cb9805fc | RUNNING    | 172.31.10.87:2678689 |      129 |        10 | True        | False        | 0.00102475  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_2733401d | PENDING    |                      |      130 |        10 | True        | False        | 0.00123882  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 44 more trials not shown (9 TERMINATED, 33 ERROR)\n",
      "Number of errored trials: 40\n",
      "Table truncated to 20 rows (20 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 3 | layer          | Linear           | 405   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 409       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 409       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680055)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:52 (running for 00:03:42.49)\n",
      "Memory usage on this node: 80.3/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 70/100 (46 ERROR, 1 PENDING, 7 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_2733401d | RUNNING    | 172.31.10.87:2680318 |      130 |        10 | True        | False        | 0.00123882  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_5477d387 | RUNNING    | 172.31.10.87:2680320 |      126 |         9 | True        | False        | 0.000753734 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_99b79f5a | RUNNING    | 172.31.10.87:2680373 |       13 |         9 | True        | False        | 0.00085627  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_da04cd3f | RUNNING    | 172.31.10.87:2680422 |       10 |        10 | True        | False        | 0.000962763 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_e128fbd6 | RUNNING    | 172.31.10.87:2680322 |       17 |        10 | True        | False        | 0.000683045 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_eadf06e9 | RUNNING    | 172.31.10.87:2680371 |       10 |         9 | True        | False        | 0.00129476  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_d9aa9748 | PENDING    |                      |      129 |         9 | True        | False        | 0.00113541  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 50 more trials not shown (9 TERMINATED, 39 ERROR)\n",
      "Number of errored trials: 46\n",
      "Table truncated to 20 rows (26 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 3 | layer          | Linear           | 477   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 481       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 481       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680373)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 3 | layer          | Linear           | 369   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 373       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 373       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680371)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 3 | layer          | Linear           | 690   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 694       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 694       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680322)\u001b[0m 0.003     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 3 | layer          | Linear           | 5.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 5.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 5.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680318)\u001b[0m 0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 3 | layer          | Linear           | 410   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 414       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 414       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680422)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 3 | layer          | Linear           | 4.5 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 4.5 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 4.5 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2680320)\u001b[0m 0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:57:58 (running for 00:03:48.39)\n",
      "Memory usage on this node: 85.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 70/100 (46 ERROR, 8 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_2733401d | RUNNING    | 172.31.10.87:2680318 |      130 |        10 | True        | False        | 0.00123882  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_5477d387 | RUNNING    | 172.31.10.87:2680320 |      126 |         9 | True        | False        | 0.000753734 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_99b79f5a | RUNNING    | 172.31.10.87:2680373 |       13 |         9 | True        | False        | 0.00085627  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_d9aa9748 | RUNNING    | 172.31.10.87:2681858 |      129 |         9 | True        | False        | 0.00113541  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_da04cd3f | RUNNING    | 172.31.10.87:2680422 |       10 |        10 | True        | False        | 0.000962763 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_e128fbd6 | RUNNING    | 172.31.10.87:2680322 |       17 |        10 | True        | False        | 0.000683045 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 50 more trials not shown (1 RUNNING, 9 TERMINATED, 39 ERROR)\n",
      "Number of errored trials: 46\n",
      "Table truncated to 20 rows (26 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:58:03 (running for 00:03:53.41)\n",
      "Memory usage on this node: 86.9/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 10.0/48 CPUs, 0.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 71/100 (52 ERROR, 1 PENDING, 2 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_d9aa9748 | RUNNING    | 172.31.10.87:2681858 |      129 |         9 | True        | False        | 0.00113541  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_3374ed88 | PENDING    |                      |        8 |         9 | True        | False        | 0.000756525 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_ac0a4644 | TERMINATED | 172.31.10.87:2668475 |      148 |         4 | False       | True         | 1.83462e-05 | False          |           16 |   96.6807 |\n",
      "| build_fit_nlinear_model_ad8e1ac8 | TERMINATED | 172.31.10.87:2666083 |       80 |         2 | False       | True         | 2.09557e-05 | False          |          256 |   81.7358 |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "| build_fit_nlinear_model_1b932dac | ERROR      | 172.31.10.87:2671114 |      142 |        10 | True        | True         | 0.00870803  | False          |           64 |           |\n",
      "| build_fit_nlinear_model_1eb26ae5 | ERROR      | 172.31.10.87:2673283 |       11 |        11 | True        | False        | 1.56264e-05 | True           |           64 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 51 more trials not shown (7 TERMINATED, 43 ERROR)\n",
      "Number of errored trials: 52\n",
      "Table truncated to 20 rows (32 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 3 | layer          | Linear           | 4.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 4.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 4.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2681858)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 3 | layer          | Linear           | 5.3 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 5.3 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 5.3 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682182)\u001b[0m 0.021     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 3 | layer          | Linear           | 369   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 373       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 373       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682314)\u001b[0m 0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 3 | layer          | Linear           | 4.2 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 4.2 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 4.2 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682184)\u001b[0m 0.017     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 3 | layer          | Linear           | 297   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 301       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 301       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682178)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 3 | layer          | Linear           | 530   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 534       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 534       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682186)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 3 | layer          | Linear           | 5.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 5.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 5.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2682236)\u001b[0m 0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:58:11 (running for 00:04:01.41)\n",
      "Memory usage on this node: 86.7/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 78/100 (54 ERROR, 1 PENDING, 7 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_112beeb4 | RUNNING    | 172.31.10.87:2683112 |      131 |         9 | True        | False        | 0.000981999 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_3374ed88 | RUNNING    | 172.31.10.87:2682178 |        8 |         9 | True        | False        | 0.000756525 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_6ea47567 | RUNNING    | 172.31.10.87:2682182 |      133 |        10 | True        | False        | 0.000679848 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_83e99a87 | RUNNING    | 172.31.10.87:2682186 |       13 |        10 | True        | False        | 0.00098332  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_9b0657d4 | RUNNING    | 172.31.10.87:2682184 |      117 |         9 | True        | False        | 0.000979628 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_af69c24b | RUNNING    | 172.31.10.87:2682236 |      128 |        10 | True        | False        | 0.000569145 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_71e0cc0c | PENDING    |                      |      128 |         9 | True        | False        | 0.00100201  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "| build_fit_nlinear_model_1a719bad | ERROR      | 172.31.10.87:2673113 |       26 |        21 | True        | False        | 0.000168689 | False          |          128 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 58 more trials not shown (9 TERMINATED, 47 ERROR)\n",
      "Number of errored trials: 54\n",
      "Table truncated to 20 rows (34 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 3 | layer          | Linear           | 4.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 4.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 4.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683112)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 3 | layer          | Linear           | 5.1 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 5.1 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 5.1 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683805)\u001b[0m 0.021     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 3 | layer          | Linear           | 4.4 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 4.4 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 4.4 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683807)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683856)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683803)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2683905)\u001b[0m 0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 3 | layer          | Linear           | 369   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 373       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 373       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684289)\u001b[0m 0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:58:20 (running for 00:04:10.41)\n",
      "Memory usage on this node: 78.6/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 40.0/48 CPUs, 3.1999999999999997/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 85/100 (60 ERROR, 1 PENDING, 8 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_51e32119 | RUNNING    | 172.31.10.87:2684289 |       10 |         9 | True        | False        | 0.00133253  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_5f7bc3df | RUNNING    | 172.31.10.87:2684740 |      129 |         9 | True        | False        | 0.00083888  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_71e0cc0c | RUNNING    | 172.31.10.87:2683803 |      128 |         9 | True        | False        | 0.00100201  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_9c14ec7b | RUNNING    | 172.31.10.87:2683807 |      122 |         9 | True        | False        | 0.00074329  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_cd75ee08 | RUNNING    | 172.31.10.87:2683805 |      128 |        10 | True        | False        | 0.000979966 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_d26c61b8 | RUNNING    | 172.31.10.87:2683856 |      128 |         9 | True        | False        | 0.00085108  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_2ab74c7e | PENDING    |                      |      132 |         9 | True        | False        | 0.000924079 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_112beeb4 | ERROR      | 172.31.10.87:2683112 |      131 |         9 | True        | False        | 0.000981999 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 65 more trials not shown (1 RUNNING, 9 TERMINATED, 53 ERROR)\n",
      "Number of errored trials: 60\n",
      "Table truncated to 20 rows (40 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 3 | layer          | Linear           | 4.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 4.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 4.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2684740)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m   rank_zero_deprecation(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 3 | layer          | Linear           | 4.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 4.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 4.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685757)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 3 | layer          | Linear           | 369   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 373       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 373       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685753)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 3 | layer          | Linear           | 297   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 301       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 301       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685755)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 3 | layer          | Linear           | 4.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 4.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 4.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2685751)\u001b[0m 0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686364)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 3 | layer          | Linear           | 530   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 534       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 534       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686307)\u001b[0m 0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-07-11 07:58:29 (running for 00:04:19.25)\n",
      "Memory usage on this node: 83.1/186.7 GiB \n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None\n",
      "Resources requested: 35.0/48 CPUs, 2.8/4 GPUs, 0.0/62.61 GiB heap, 0.0/30.83 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
      "Current best trial: feb74060 with q_smape=50.491225719451904 and parameters={'in_len': 146, 'out_len': 9, 'normalize': False, 'const_init': True, 'lr': 5.047694155596576e-05, 'include_hour': True, 'batch_size': 128}\n",
      "Result logdir: /home/ubuntu/ray_results/dlinear_tune_cov\n",
      "Number of trials: 92/100 (68 ERROR, 1 PENDING, 7 RUNNING, 16 TERMINATED)\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "| Trial name                       | status     | loc                  |   in_len |   out_len | normalize   | const_init   |          lr | include_hour   |   batch_size |   q_smape |\n",
      "|----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------|\n",
      "| build_fit_nlinear_model_2ab74c7e | RUNNING    | 172.31.10.87:2685751 |      132 |         9 | True        | False        | 0.000924079 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_3dd25a1d | RUNNING    | 172.31.10.87:2686307 |       13 |        10 | True        | False        | 0.000815195 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_552f986b | RUNNING    | 172.31.10.87:2686364 |      128 |         9 | True        | False        | 0.000861751 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_8c2e59fb | RUNNING    | 172.31.10.87:2685755 |        8 |         9 | True        | False        | 0.000786086 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_a7d7c4b8 | RUNNING    | 172.31.10.87:2686802 |      133 |         9 | True        | False        | 0.00080359  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_cb252c9a | RUNNING    | 172.31.10.87:2659586 |       64 |        22 | False       | False        | 0.000143818 | False          |           64 |           |\n",
      "| build_fit_nlinear_model_e84d3c06 | RUNNING    | 172.31.10.87:2685753 |       10 |         9 | True        | False        | 0.000772078 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_469e83a5 | PENDING    |                      |       16 |         9 | True        | False        | 0.000732859 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_06c8d9a1 | TERMINATED | 172.31.10.87:2668469 |      110 |        19 | False       | False        | 6.25249e-05 | True           |          128 |  169.015  |\n",
      "| build_fit_nlinear_model_26bb9eb6 | TERMINATED | 172.31.10.87:2671836 |       40 |        10 | False       | True         | 4.84494e-05 | True           |           64 |   87.3337 |\n",
      "| build_fit_nlinear_model_3c68e519 | TERMINATED | 172.31.10.87:2670113 |      160 |         1 | False       | True         | 0.00917525  | False          |          256 |  174.302  |\n",
      "| build_fit_nlinear_model_4acdf74f | TERMINATED | 172.31.10.87:2663300 |      107 |        21 | False       | False        | 0.000176996 | False          |          128 |   73.2786 |\n",
      "| build_fit_nlinear_model_52883244 | TERMINATED | 172.31.10.87:2662821 |      141 |        17 | False       | True         | 0.00357606  | False          |           16 |  165.095  |\n",
      "| build_fit_nlinear_model_85c62b7a | TERMINATED | 172.31.10.87:2660923 |      154 |        20 | False       | False        | 9.40394e-05 | False          |          128 |  108.204  |\n",
      "| build_fit_nlinear_model_89536f7c | TERMINATED | 172.31.10.87:2660277 |       89 |        15 | False       | True         | 0.0142686   | False          |           32 |  166.811  |\n",
      "| build_fit_nlinear_model_03542bb7 | ERROR      | 172.31.10.87:2674221 |       82 |        12 | True        | False        | 0.00106381  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_0a369a68 | ERROR      | 172.31.10.87:2669339 |        8 |        18 | True        | True         | 9.84963e-05 | True           |           16 |           |\n",
      "| build_fit_nlinear_model_0f3a7ae8 | ERROR      | 172.31.10.87:2660925 |      100 |         1 | True        | False        | 0.000114864 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_112beeb4 | ERROR      | 172.31.10.87:2683112 |      131 |         9 | True        | False        | 0.000981999 | True           |          128 |           |\n",
      "| build_fit_nlinear_model_12f2a79e | ERROR      | 172.31.10.87:2660913 |       53 |         7 | True        | False        | 0.0507138   | True           |           64 |           |\n",
      "| build_fit_nlinear_model_15b489a7 | ERROR      | 172.31.10.87:2675636 |       78 |        13 | True        | False        | 0.00090524  | True           |          128 |           |\n",
      "| build_fit_nlinear_model_17cb88ed | ERROR      | 172.31.10.87:2678200 |      130 |        11 | True        | False        | 0.0010849   | True           |          256 |           |\n",
      "+----------------------------------+------------+----------------------+----------+-----------+-------------+--------------+-------------+----------------+--------------+-----------+\n",
      "... 72 more trials not shown (9 TERMINATED, 61 ERROR)\n",
      "Number of errored trials: 68\n",
      "Table truncated to 20 rows (48 overflow)\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name                       |   # failures | error file                                                                                                                                                                                                 |\n",
      "|----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| build_fit_nlinear_model_b0f3656a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_b0f3656a_2_batch_size=16,const_init=False,in_len=50,include_hour=False,lr=0.0004,normalize=True,out_len=22_2023-07-11_07-54-15/error.txt |\n",
      "| build_fit_nlinear_model_12f2a79e |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_12f2a79e_4_batch_size=64,const_init=False,in_len=53,include_hour=True,lr=0.0507,normalize=True,out_len=7_2023-07-11_07-54-26/error.txt   |\n",
      "| build_fit_nlinear_model_92a8b3ee |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_92a8b3ee_5_batch_size=256,const_init=False,in_len=33,include_hour=False,lr=0.0001,normalize=True,out_len=8_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_e6bc2e6c |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_e6bc2e6c_6_batch_size=256,const_init=False,in_len=139,include_hour=True,lr=0.0000,normalize=True,out_len=2_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_0f3a7ae8 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0f3a7ae8_9_batch_size=128,const_init=False,in_len=100,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-54-26/error.txt |\n",
      "| build_fit_nlinear_model_c6db46a9 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_c6db46a9_14_batch_size=128,const_init=True,in_len=146,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-54-54/error.txt |\n",
      "| build_fit_nlinear_model_276e3911 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_276e3911_16_batch_size=32,const_init=True,in_len=67,include_hour=False,lr=0.0106,normalize=True,out_len=19_2023-07-11_07-55-04/error.txt |\n",
      "| build_fit_nlinear_model_f58b4366 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f58b4366_17_batch_size=32,const_init=True,in_len=88,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-12/error.txt   |\n",
      "| build_fit_nlinear_model_d036aeba |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_d036aeba_19_batch_size=256,const_init=True,in_len=158,include_hour=True,lr=0.0002,normalize=True,out_len=2_2023-07-11_07-55-32/error.txt |\n",
      "| build_fit_nlinear_model_3afa1bde |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_3afa1bde_20_batch_size=16,const_init=True,in_len=58,include_hour=True,lr=0.0001,normalize=True,out_len=1_2023-07-11_07-55-38/error.txt   |\n",
      "| build_fit_nlinear_model_afb75e49 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_afb75e49_21_batch_size=256,const_init=False,in_len=152,include_hour=False,lr=0.0112,normalize=True,out_len_2023-07-11_07-55-46/error.txt |\n",
      "| build_fit_nlinear_model_f25d8dd7 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_f25d8dd7_24_batch_size=32,const_init=True,in_len=112,include_hour=True,lr=0.0008,normalize=True,out_len=13_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_5f17d49b |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_5f17d49b_25_batch_size=16,const_init=False,in_len=144,include_hour=True,lr=0.0000,normalize=True,out_len=1_2023-07-11_07-55-52/error.txt |\n",
      "| build_fit_nlinear_model_0a369a68 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_0a369a68_26_batch_size=16,const_init=True,in_len=8,include_hour=True,lr=0.0001,normalize=True,out_len=18_2023-07-11_07-55-55/error.txt   |\n",
      "| build_fit_nlinear_model_8ba05c9a |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_8ba05c9a_29_batch_size=64,const_init=False,in_len=153,include_hour=False,lr=0.0043,normalize=True,out_len=_2023-07-11_07-56-04/error.txt |\n",
      "| build_fit_nlinear_model_1b932dac |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1b932dac_30_batch_size=64,const_init=True,in_len=142,include_hour=False,lr=0.0087,normalize=True,out_len=1_2023-07-11_07-56-12/error.txt |\n",
      "| build_fit_nlinear_model_6e090e40 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_6e090e40_31_batch_size=16,const_init=False,in_len=150,include_hour=True,lr=0.0066,normalize=True,out_len=1_2023-07-11_07-56-13/error.txt |\n",
      "| build_fit_nlinear_model_21ea8994 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_21ea8994_34_batch_size=64,const_init=False,in_len=142,include_hour=False,lr=0.0000,normalize=True,out_len=_2023-07-11_07-56-34/error.txt |\n",
      "| build_fit_nlinear_model_1a719bad |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1a719bad_36_batch_size=128,const_init=False,in_len=26,include_hour=False,lr=0.0002,normalize=True,out_len=_2023-07-11_07-56-48/error.txt |\n",
      "| build_fit_nlinear_model_1eb26ae5 |            1 | /home/ubuntu/ray_results/dlinear_tune_cov/build_fit_nlinear_model_1eb26ae5_37_batch_size=64,const_init=False,in_len=11,include_hour=True,lr=0.0000,normalize=True,out_len=11_2023-07-11_07-56-49/error.txt |\n",
      "+----------------------------------+--------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 3 | layer          | Linear           | 4.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 4.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 4.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2686802)\u001b[0m 0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m \r",
      "Predicting: 0it [00:00, ?it/s]\r",
      "Predicting:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.27it/s]\r",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2659586)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m Global seed set to 42\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=-1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=-1)` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m /home/ubuntu/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687676)\u001b[0m 0.018     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 3 | layer          | Linear           | 4.6 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 4.6 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 4.6 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687625)\u001b[0m 0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 3 | layer          | Linear           | 4.8 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 4.8 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 4.8 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687574)\u001b[0m 0.019     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 3 | layer          | Linear           | 330   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 334       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 334       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687674)\u001b[0m 0.001     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m Auto select gpus: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 3 | layer          | Linear           | 585   \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 589       Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 589       Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687571)\u001b[0m 0.002     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m   | Name           | Type             | Params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 0 | criterion      | SmapeLoss        | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 1 | train_metrics  | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 2 | val_metrics    | MetricCollection | 0     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 3 | layer          | Linear           | 4.7 K \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 4 | linear_fut_cov | Linear           | 4     \n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m ----------------------------------------------------\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 4.7 K     Trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 4.7 K     Total params\n",
      "\u001b[2m\u001b[36m(build_fit_nlinear_model pid=2687576)\u001b[0m 0.019     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "# from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler, AsyncHyperBandScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "# tune_callback = TuneReportCallback(\n",
    "#     {\n",
    "#         \"loss\":\"val_loss\",\n",
    "#         \"sMAPE\": \"val_SymmetricMeanAbsolutePercentageError\",\n",
    "#     },\n",
    "#     on=\"validation_end\",\n",
    "# )\n",
    "\n",
    "early_stopper = EarlyStopping(\n",
    "        monitor=\"val_SymmetricMeanAbsolutePercentageError\",\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "    )\n",
    "\n",
    "#define the hyperparameter search space\n",
    "config = {\n",
    "    \"in_len\": tune.randint(8,168),#setting 168 is not a good option here as convolutions take time reducing this to 80\n",
    "    \"out_len\":tune.randint(1,24),\n",
    "    \"normalize\": tune.choice([True, False]),\n",
    "    \"const_init\":tune.choice([True, False]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"include_hour\":tune.choice([True, False]),\n",
    "    \"batch_size\":tune.choice([16,32,64,128,256]),\n",
    "    \n",
    "}\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=list(config.keys()),\n",
    "    metric_columns=[\"q_smape\"])\n",
    "resources_per_trial = {\"cpu\": 5, \"gpu\": 0.4}\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "algo = OptunaSearch()\n",
    "\n",
    "algo = ConcurrencyLimiter(algo, max_concurrent=10)\n",
    "\n",
    "scheduler = AsyncHyperBandScheduler(max_t=100, grace_period=10, reduction_factor=2)\n",
    "\n",
    "train_fn_with_parameters = tune.with_parameters(build_fit_nlinear_model, callbacks=[early_stopper])\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_fn_with_parameters,\n",
    "    resources_per_trial=resources_per_trial,\n",
    "    metric=\"q_smape\",\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    search_alg=algo,\n",
    "    scheduler = scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"dlinear_tune_cov\",\n",
    "    raise_on_failed_trial=False\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "        monitor=\"val_SymmetricMeanAbsolutePercentageError\",\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "    )\n",
    "best_model = build_fit_nlinear_model_return(analysis.best_config, callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_tpred = best_model.predict(\n",
    "                series = ts_ttrain,\n",
    "                future_covariates=covF_t,\n",
    "                n = len(ts_ttest),\n",
    "                verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.DataFrame()\n",
    "dfY['Actual'] = TimeSeries.pd_series(ts_test)\n",
    "def pred(ts_tpred, ts_test):\n",
    "    ts_tpred = scalerP.inverse_transform(ts_tpred)\n",
    "    s = TimeSeries.pd_series(ts_tpred)\n",
    "    header = \"Predicted\"\n",
    "    dfY[header] = s\n",
    "    q_smape = smape(ts_tpred, ts_test)\n",
    "    print('SMAPE:',q_smape)\n",
    "pred(ts_tpred, ts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the forecast\n",
    "plt.figure(100, figsize=(20, 7))\n",
    "plt.plot(dfY.index, dfY['Predicted'], color='r', label='Predicted')\n",
    "plt.plot(dfY.index, dfY['Actual'], color='c', label='Actual Radon Value')\n",
    "plt.legend()\n",
    "plt.title('Radon Prediction for test set')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Radon(pCi/L)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radon 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_radon['13'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising the Radon signal\n",
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db4', level=5):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    n = len(x) \n",
    "    sigma = (1/0.6745) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    if len(x) % 2 ==0:\n",
    "        return pywt.waverec(coeff, wavelet, mode='per')\n",
    "    else:\n",
    "        return pywt.waverec(coeff, wavelet, mode='per')[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = df['Radon'].copy()\n",
    "wavelet_name='coif17'\n",
    "filtered = wavelet_denoising(signal, wavelet=wavelet_name, level=4)\n",
    "df['Radon'] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station = pd.read_csv('weather_data_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station.drop('Date', axis=1, inplace=True)\n",
    "weather_station['Simple Date'] = pd.to_datetime(weather_station['Simple Date'])\n",
    "weather_station.sort_values(by='Simple Date', ascending=True, inplace=True)\n",
    "weather_station['Simple Date'] = weather_station['Simple Date'].dt.floor('H')\n",
    "weather_station = weather_station.resample('H', on = 'Simple Date').mean()\n",
    "weather_station = weather_station.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in weather_station.columns:\n",
    "    df[column] = weather_station[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any missing values?\n",
    "def gaps(df):\n",
    "    if df.isnull().values.any():\n",
    "        print(\"MISSING values:\\n\")\n",
    "        mno.matrix(df)\n",
    "    else:\n",
    "        print(\"no missing values\\n\")\n",
    "gaps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df[column] = df[column].astype('float32')\n",
    "    if column == 'Radon':\n",
    "        continue\n",
    "    else:\n",
    "        for i in range(1,40):\n",
    "            df[column+'_lag_'+str(i)] = df[column].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlations of features with price\n",
    "df_corr = df.corr(method=\"spearman\")\n",
    "print(df_corr.shape)\n",
    "print(\"correlation with Radon:\")\n",
    "df_corrP = pd.DataFrame(df_corr[\"Radon\"].sort_values(ascending=False))\n",
    "df_corrP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest absolute correlations with Radon\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "df_corrH = df_corrP[(df_corrP[\"Radon\"]) >= 0.54103]\n",
    "df_corrH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method: correlation matrix as heatmap\n",
    "def corr_heatmap(df):\n",
    "    idx = df.corr().sort_values(\"Radon\", ascending=False).index\n",
    "    df_sorted = df.loc[:, idx]  # sort dataframe columns by their correlation \n",
    "\n",
    "    #plt.figure(figsize = (15,15))\n",
    "    sns.set(font_scale=0.75)\n",
    "    ax = sns.heatmap(df_sorted.corr(method='spearman').round(3), \n",
    "            annot=True, \n",
    "            square=True, \n",
    "            linewidths=.75, cmap=\"coolwarm\", \n",
    "            fmt = \".2f\", \n",
    "            annot_kws = {\"size\": 11})\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.title(\"correlation matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# visualize correlations with price     \n",
    "\n",
    "df4 = df[df_corrH.index]   # keep the components with at least modest correlations\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "corr_heatmap(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series object for target variable\n",
    "ts_P = TimeSeries.from_series(df4[\"Radon\"], fill_missing_dates=True, freq=\"H\") \n",
    "\n",
    "# check attributes of the time series\n",
    "print(\"components:\", ts_P.components)\n",
    "print(\"duration:\",ts_P.duration)\n",
    "print(\"frequency:\",ts_P.freq)\n",
    "print(\"frequency:\",ts_P.freq_str)\n",
    "print(\"has date time index? (or else, it must have an integer index):\",ts_P.has_datetime_index)\n",
    "print(\"deterministic:\",ts_P.is_deterministic)\n",
    "print(\"univariate:\",ts_P.is_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time series object for the feature columns\n",
    "df_covF = df4.loc[:, df4.columns != \"Radon\"]\n",
    "df_covF = df_covF.loc[:, df_covF.columns != 'Outdoor h Temperature (°F)']\n",
    "ts_covF = TimeSeries.from_dataframe(df_covF, fill_missing_dates=True, freq=\"H\")\n",
    "\n",
    "# check attributes of the time series\n",
    "print(\"components (columns) of feature time series:\", ts_covF.components)\n",
    "print(\"duration:\",ts_covF.duration)\n",
    "print(\"frequency:\",ts_covF.freq)\n",
    "print(\"frequency:\",ts_covF.freq_str)\n",
    "print(\"has date time index? (or else, it must have an integer index):\",ts_covF.has_datetime_index)\n",
    "print(\"deterministic:\",ts_covF.is_deterministic)\n",
    "print(\"univariate:\",ts_covF.is_univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a 3-dimensional numpy array from a time series object\n",
    "# 3 dimensions: time (rows) / components (columns) / samples\n",
    "ar_covF = ts_covF.all_values()\n",
    "print(type(ar_covF))\n",
    "ar_covF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a pandas series or dataframe from a time series object\n",
    "df_covF = ts_covF.pd_dataframe()\n",
    "type(df_covF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a 3-dimensional numpy array from a time series object\n",
    "# 3 dimensions: time (rows) / components (columns) / samples\n",
    "ar_covF = ts_covF.all_values()\n",
    "print(type(ar_covF))\n",
    "ar_covF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: operating with time series objects:\n",
    "# we can also create a pandas series or dataframe from a time series object\n",
    "df_covF = ts_covF.pd_dataframe()\n",
    "type(df_covF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split and scaling of target variable\n",
    "ts_train, ts_test = ts_P.split_after(split_point=9210)\n",
    "\n",
    "print(\"training start:\", ts_train.start_time())\n",
    "print(\"training end:\", ts_train.end_time())\n",
    "print(\"training duration:\",ts_train.duration)\n",
    "print(\"test start:\", ts_test.start_time())\n",
    "print(\"test end:\", ts_test.end_time())\n",
    "print(\"test duration:\", ts_test.duration)\n",
    "\n",
    "\n",
    "scalerP = Scaler()\n",
    "scalerP.fit_transform(ts_train)\n",
    "ts_ttrain = scalerP.transform(ts_train)\n",
    "ts_ttest = scalerP.transform(ts_test)    \n",
    "ts_t = scalerP.transform(ts_P)\n",
    "\n",
    "# make sure data are of type float\n",
    "ts_t = ts_t.astype(np.float32)\n",
    "ts_ttrain = ts_ttrain.astype(np.float32)\n",
    "ts_ttest = ts_ttest.astype(np.float32)\n",
    "\n",
    "print(\"first and last row of scaled Radon time series:\")\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "ts_t.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split and scaling of feature covariates\n",
    "covF_train, covF_test = ts_covF.split_after(split_point=9210)\n",
    "\n",
    "scalerF = Scaler()\n",
    "scalerF.fit_transform(covF_train)\n",
    "covF_ttrain = scalerF.transform(covF_train) \n",
    "covF_ttest = scalerF.transform(covF_test)   \n",
    "covF_t = scalerF.transform(ts_covF)  \n",
    "# covF_t = ts_covF\n",
    "# covF_ttrain = covF_train\n",
    "# covF_ttest = covF_test\n",
    "# make sure data are of type float\n",
    "covF_ttrain = covF_ttrain.astype(np.float32)\n",
    "covF_ttest = covF_ttest.astype(np.float32)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(\"first and last row of scaled feature covariates:\")\n",
    "covF_t.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"first and last row of scaled target variable in training set: price:\")\n",
    "ts_ttrain.pd_dataframe().iloc[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed_value):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(seed_value, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ray.air import session\n",
    "from darts.utils.losses import SmapeLoss\n",
    "from torchmetrics import MetricCollection, SymmetricMeanAbsolutePercentageError, MeanAbsolutePercentageError\n",
    "def build_fit_nlinear_model(\n",
    "    model_args,\n",
    "    save_checkpoints=False,\n",
    "    callbacks=None,\n",
    "    save_model=False\n",
    "):\n",
    "#     BATCH_SIZE=64\n",
    "    MAX_EPOCHS=500\n",
    "    NR_EPOCHS_VAL_PERIOD=1\n",
    "    set_seed(42)\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), SymmetricMeanAbsolutePercentageError()])\n",
    "\n",
    "#     early_stopper = EarlyStopping(\n",
    "#         monitor=\"val_loss\",\n",
    "#         patience=5,\n",
    "#         min_delta=0.001,\n",
    "#         mode='min',\n",
    "#     )\n",
    "\n",
    "#     if callbacks is None:\n",
    "#         callbacks = [early_stopper]\n",
    "#     else:\n",
    "#         callbacks.append(early_stopper)\n",
    "    \n",
    "    #detect if GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         pl_trainer_kwargs = {\n",
    "#             \"accelerator\": \"gpu\",\n",
    "#             \"gpus\": -1,\n",
    "#             \"auto_select_gpus\": True,\n",
    "#             \"callbacks\": callbacks,\n",
    "#             \"enable_progress_bar\":False,\n",
    "#         }\n",
    "#         num_workers=8\n",
    "#     else:\n",
    "#         pl_trainer_kwargs={\n",
    "#             \"callbacks\": callbacks,\n",
    "#         }\n",
    "#         num_workers=0\n",
    "    pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"gpus\":-1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"enable_progress_bar\": False,\n",
    "        }\n",
    "    encoders={\"cyclic\": {\"future\": [\"hour\"]},\n",
    "             'transformer':Scaler()} if model_args['include_hour'] else None\n",
    "   \n",
    "\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=model_args['in_len'],\n",
    "        output_chunk_length=model_args['out_len'],\n",
    "        batch_size=model_args['batch_size'],\n",
    "        n_epochs=MAX_EPOCHS,\n",
    "        nr_epochs_val_period=NR_EPOCHS_VAL_PERIOD,\n",
    "        model_name=\"NLinear\",\n",
    "        shared_weights=False,\n",
    "        normalize=model_args['normalize'],\n",
    "        const_init=model_args['const_init'],\n",
    "        use_static_covariates=False,\n",
    "        loss_fn=SmapeLoss(),\n",
    "        optimizer_kwargs={'lr': model_args['lr']},\n",
    "        add_encoders=encoders,\n",
    "        log_tensorboard=False,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        torch_metrics=torch_metrics,\n",
    "        random_state=42\n",
    "        )\n",
    "    val_len = len(ts_test)\n",
    "    val_series = ts_ttrain[-((val_len) + model_args['in_len']) :]\n",
    "    ts_ttrain_input = ts_ttrain[:-(val_len )]\n",
    "    model.fit(  ts_ttrain_input, \n",
    "                future_covariates=covF_t,\n",
    "                val_series=val_series,\n",
    "                val_future_covariates=covF_t,)\n",
    "#     model.load_from_checkpoint(f\"{model_args['model']} RNN model\", best=True)\n",
    "    ts_tpred = model.predict(\n",
    "                series = ts_ttrain,\n",
    "                future_covariates=covF_t,\n",
    "                n = len(ts_ttest),\n",
    "                verbose=True\n",
    "    )\n",
    "    ts_q = scalerP.inverse_transform(ts_tpred)\n",
    "    q_smape = smape(ts_q, ts_test)\n",
    "    session.report({'q_smape': q_smape})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fit_nlinear_model_return(\n",
    "    model_args,\n",
    "    save_checkpoints=False,\n",
    "    callbacks=None,\n",
    "    save_model=False\n",
    "):\n",
    "#     BATCH_SIZE=64\n",
    "    MAX_EPOCHS=500\n",
    "    NR_EPOCHS_VAL_PERIOD=1\n",
    "    set_seed(42)\n",
    "    torch_metrics = MetricCollection([MeanAbsolutePercentageError(), SymmetricMeanAbsolutePercentageError()])\n",
    "\n",
    "#     early_stopper = EarlyStopping(\n",
    "#         monitor=\"val_loss\",\n",
    "#         patience=5,\n",
    "#         min_delta=0.001,\n",
    "#         mode='min',\n",
    "#     )\n",
    "\n",
    "#     if callbacks is None:\n",
    "#         callbacks = [early_stopper]\n",
    "#     else:\n",
    "#         callbacks.append(early_stopper)\n",
    "    \n",
    "    #detect if GPU is available\n",
    "#     if torch.cuda.is_available():\n",
    "#         pl_trainer_kwargs = {\n",
    "#             \"accelerator\": \"gpu\",\n",
    "#             \"gpus\": -1,\n",
    "#             \"auto_select_gpus\": True,\n",
    "#             \"callbacks\": callbacks,\n",
    "#             \"enable_progress_bar\":False,\n",
    "#         }\n",
    "#         num_workers=8\n",
    "#     else:\n",
    "#         pl_trainer_kwargs={\n",
    "#             \"callbacks\": callbacks,\n",
    "#         }\n",
    "#         num_workers=0\n",
    "    pl_trainer_kwargs={\n",
    "            \"accelerator\": \"gpu\",\n",
    "            \"devices\":1,\n",
    "            \"auto_select_gpus\": True,\n",
    "            \"callbacks\": callbacks,\n",
    "            \"enable_progress_bar\": True,\n",
    "        }\n",
    "    encoders={\"cyclic\": {\"future\": [\"hour\"]},\n",
    "             'transformer':Scaler()} if model_args['include_hour'] else None\n",
    "   \n",
    "\n",
    "    model = NLinearModel(\n",
    "        input_chunk_length=model_args['in_len'],\n",
    "        output_chunk_length=model_args['out_len'],\n",
    "        batch_size=model_args['batch_size'],\n",
    "        n_epochs=MAX_EPOCHS,\n",
    "        nr_epochs_val_period=NR_EPOCHS_VAL_PERIOD,\n",
    "        model_name=\"DLinear\",\n",
    "        shared_weights=False,\n",
    "        const_init=model_args['const_init'],\n",
    "        normalize=model_args['normalize'],\n",
    "        use_static_covariates=False,\n",
    "        loss_fn=SmapeLoss(),\n",
    "        optimizer_kwargs={'lr': model_args['lr']},\n",
    "        add_encoders=encoders,\n",
    "        log_tensorboard=False,\n",
    "        force_reset=True,\n",
    "        save_checkpoints=save_checkpoints,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        torch_metrics=torch_metrics,\n",
    "        random_state=42\n",
    "        )\n",
    "    val_len = len(ts_test)\n",
    "    val_series = ts_ttrain[-((val_len) + model_args['in_len']) :]\n",
    "    ts_ttrain_input = ts_ttrain[:-(val_len )]\n",
    "    model.fit(  ts_ttrain_input, \n",
    "                future_covariates=covF_t,\n",
    "                val_series=val_series,\n",
    "                val_future_covariates=covF_t,)\n",
    "#     model.load_from_checkpoint(f\"{model_args['model']} RNN model\", best=True)\n",
    "#     ts_tpred = model.predict(\n",
    "#                 series = ts_ttrain,\n",
    "#                 past_covariates=covF_t,\n",
    "#                 n = len(ts_ttest),\n",
    "#                 verbose=True\n",
    "#     )\n",
    "#     ts_q = scalerP.inverse_transform(ts_tpred)\n",
    "#     q_smape = smape(ts_q, ts_test)\n",
    "#     session.report({'q_smape': q_smape})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "# from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler, AsyncHyperBandScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "# tune_callback = TuneReportCallback(\n",
    "#     {\n",
    "#         \"loss\":\"val_loss\",\n",
    "#         \"sMAPE\": \"val_SymmetricMeanAbsolutePercentageError\",\n",
    "#     },\n",
    "#     on=\"validation_end\",\n",
    "# )\n",
    "\n",
    "early_stopper = EarlyStopping(\n",
    "        monitor=\"val_SymmetricMeanAbsolutePercentageError\",\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "    )\n",
    "\n",
    "#define the hyperparameter search space\n",
    "config = {\n",
    "    \"in_len\": tune.randint(8,168),#setting 168 is not a good option here as convolutions take time reducing this to 80\n",
    "    \"out_len\":tune.randint(1,24),\n",
    "    \"normalize\": tune.choice([True, False]),\n",
    "    \"const_init\":tune.choice([True, False]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"include_hour\":tune.choice([True, False]),\n",
    "    \"batch_size\":tune.choice([16,32,64,128,256]),\n",
    "    \n",
    "}\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=list(config.keys()),\n",
    "    metric_columns=[\"q_smape\"])\n",
    "resources_per_trial = {\"cpu\": 5, \"gpu\": 0.4}\n",
    "\n",
    "num_samples = 100\n",
    "\n",
    "algo = OptunaSearch()\n",
    "\n",
    "algo = ConcurrencyLimiter(algo, max_concurrent=10)\n",
    "\n",
    "scheduler = AsyncHyperBandScheduler(max_t=100, grace_period=10, reduction_factor=2)\n",
    "\n",
    "train_fn_with_parameters = tune.with_parameters(build_fit_nlinear_model, callbacks=[early_stopper])\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_fn_with_parameters,\n",
    "    resources_per_trial=resources_per_trial,\n",
    "    metric=\"q_smape\",\n",
    "    mode=\"min\",\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    search_alg=algo,\n",
    "    scheduler = scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    name=\"dlinear_tune_cov\",\n",
    "    raise_on_failed_trial=False\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters found were: \", analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "        monitor=\"val_SymmetricMeanAbsolutePercentageError\",\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "    )\n",
    "best_model = build_fit_nlinear_model_return(analysis.best_config, callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_tpred = best_model.predict(\n",
    "                series = ts_ttrain,\n",
    "                future_covariates=covF_t,\n",
    "                n = len(ts_ttest),\n",
    "                verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfY = pd.DataFrame()\n",
    "dfY['Actual'] = TimeSeries.pd_series(ts_test)\n",
    "def pred(ts_tpred, ts_test):\n",
    "    ts_tpred = scalerP.inverse_transform(ts_tpred)\n",
    "    s = TimeSeries.pd_series(ts_tpred)\n",
    "    header = \"Predicted\"\n",
    "    dfY[header] = s\n",
    "    q_smape = smape(ts_tpred, ts_test)\n",
    "    print('SMAPE:',q_smape)\n",
    "pred(ts_tpred, ts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the forecast\n",
    "plt.figure(100, figsize=(20, 7))\n",
    "plt.plot(dfY.index, dfY['Predicted'], color='r', label='Predicted')\n",
    "plt.plot(dfY.index, dfY['Actual'], color='c', label='Actual Radon Value')\n",
    "plt.legend()\n",
    "plt.title('Radon Prediction for test set')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Radon(pCi/L)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "db1181248e206fa5ba9eaccbec5f3b4789d8441acf18a85eb80b837590041d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
